{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c080c799-037f-45b0-bdee-d0989464b187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 1. Data reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bdeba03-50eb-426b-8ed6-22da94d9fa64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "reading the \"Pigments\" Dataset, provided in an emial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd906017-bc3c-403e-9833-dcd189b447bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First load the libraries / modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ff6b26-c729-4827-963e-21120b6c47ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the needed python libraries by executing this python code (press ctrl enter)\n",
    "%pip install numpy scipy matplotlib pandas\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4536435-1a56-4f66-8b81-a8563b0de6ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load the dataset into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3068ccd4-26ef-487e-ae99-b8958ecce1a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL zur Datei (GitHub)\n",
    "url = \"https://raw.githubusercontent.com/Tao-Pi/CAS-Applied-Data-Science-GroupWork/refs/heads/main/data%2C%20calculations%2C%20results/Pigments_Version202509051820.csv\"\n",
    "\n",
    "# CSV einlesen und leere Zeilen überspringen\n",
    "df = pd.read_csv(url, skip_blank_lines=True)\n",
    "\n",
    "# Ausgabe prüfen\n",
    "print(df.head())\n",
    "print(f\"\\nShape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da411ef1-d9b3-4e32-a613-ec6a081d8462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Browse through all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cda211cc-aabe-485f-ae3b-7f23c2c1ffd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc8ffbb7-e0f1-4165-bb2f-02e0d08e4a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "change col names to more descriptive names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f264db-86e5-48e9-ae92-b028b421a3e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'name': 'sample',\n",
    "    'RABD670': 'green pigments: index',\n",
    "    'TChl-a': 'green pigments: direct concentration measurement (ug/g)',\n",
    "    'locality': 'locality',\n",
    "    'OC': 'organic carbon content in %'\n",
    "}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee6572e-daef-43ad-b64b-7ac98c99c735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Print some descriptive statistics, using pandas summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4af46b6-6c39-4a8c-85c0-97e0d07705f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dc50b6e-9ad4-4d12-bafe-28d3f99214ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 02 Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb5d7f9b-d37c-453e-a5bb-94707e975d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Descriptive statistics & plots for:\n",
    "#     - \"green pigments: index\"\n",
    "#     - \"green pigments: direct concentration measurement (ug/g)\"\n",
    "# Append this block AFTER your df.rename(...) and df.describe().\n",
    "\n",
    "from scipy import stats  # already imported as scipy.stats; this just gives 'stats' alias if needed\n",
    "\n",
    "# Column aliases (matches your renamed columns)\n",
    "col_x = \"green pigments: index\"\n",
    "col_y = \"green pigments: direct concentration measurement (ug/g)\"\n",
    "\n",
    "# Pairwise-clean data\n",
    "df_pair = df.dropna(subset=[col_x, col_y]).copy()\n",
    "\n",
    "# ---------- Descriptive statistics ----------\n",
    "def describe_series(s: pd.Series) -> pd.Series:\n",
    "    s_clean = s.dropna()\n",
    "    out = pd.Series(dtype=\"float64\")\n",
    "    out[\"count\"] = s_clean.shape[0]\n",
    "    out[\"missing\"] = s.shape[0] - s_clean.shape[0]\n",
    "    out[\"missing_%\"] = 100 * (1 - s_clean.shape[0] / s.shape[0]) if s.shape[0] else float(\"nan\")\n",
    "    out[\"mean\"] = s_clean.mean()\n",
    "    out[\"std\"] = s_clean.std(ddof=1)\n",
    "    out[\"cv (std/mean)\"] = (out[\"std\"] / out[\"mean\"]) if out[\"mean\"] not in (0, None) else float(\"nan\")\n",
    "    out[\"min\"] = s_clean.min()\n",
    "    out[\"q1\"] = s_clean.quantile(0.25)\n",
    "    out[\"median\"] = s_clean.median()\n",
    "    out[\"q3\"] = s_clean.quantile(0.75)\n",
    "    out[\"iqr\"] = out[\"q3\"] - out[\"q1\"]\n",
    "    out[\"max\"] = s_clean.max()\n",
    "    out[\"skewness\"] = stats.skew(s_clean, bias=False)\n",
    "    out[\"kurtosis (excess)\"] = stats.kurtosis(s_clean, fisher=True, bias=False)\n",
    "    if 3 <= len(s_clean) <= 5000:\n",
    "        W, p = stats.shapiro(s_clean)\n",
    "        out[\"shapiro_W\"] = W\n",
    "        out[\"shapiro_p\"] = p\n",
    "    else:\n",
    "        out[\"shapiro_W\"] = float(\"nan\")\n",
    "        out[\"shapiro_p\"] = float(\"nan\")\n",
    "    return out\n",
    "\n",
    "desc_table = pd.DataFrame({\n",
    "    col_x: describe_series(df[col_x]),\n",
    "    col_y: describe_series(df[col_y]),\n",
    "})\n",
    "print(\"\\n=== Descriptive statistics ===\")\n",
    "print(desc_table.round(4))\n",
    "\n",
    "# ---------- Correlation tests ----------\n",
    "pearson_r, pearson_p = stats.pearsonr(df_pair[col_x], df_pair[col_y])\n",
    "spearman_r, spearman_p = stats.spearmanr(df_pair[col_x], df_pair[col_y])\n",
    "kendall_tau, kendall_p = stats.kendalltau(df_pair[col_x], df_pair[col_y])\n",
    "\n",
    "corr_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"statistic\": [\"Pearson r\", \"Spearman ρ\", \"Kendall τ\"],\n",
    "        \"value\": [pearson_r, spearman_r, kendall_tau],\n",
    "        \"p_value\": [pearson_p, spearman_p, kendall_p],\n",
    "    }\n",
    ")\n",
    "print(\"\\n=== Correlation tests (pairwise complete) ===\")\n",
    "print(corr_tbl.round(6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6da0bf2-d91c-41b8-b307-6f22e28994f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Plot 01: Histogram and box plot for the measures of pigments\n",
    "#     (Index and Direct concentration measurement of green pigments (µg/g)) in different samples\n",
    "\n",
    "# cm to inches conversion\n",
    "cm_to_inch = 1/2.54\n",
    "fig_width = 24.2 * cm_to_inch\n",
    "fig_height = 10.08 * cm_to_inch\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(fig_width, fig_height))\n",
    "fig.suptitle(\n",
    "    \"Plot 01: Histogram and box plot for the measures of pigments\\n\"\n",
    "    \"(Index and Direct concentration measurement of green pigments (µg/g)) in different samples\",\n",
    "    fontsize=11,\n",
    "    weight=\"bold\"\n",
    ")\n",
    "\n",
    "col_x = \"green pigments: index\"\n",
    "col_y = \"green pigments: direct concentration measurement (ug/g)\"\n",
    "\n",
    "# Histogram for index\n",
    "axes[0,0].hist(df[col_x].dropna(), bins=20)\n",
    "axes[0,0].set_title(\"Histogram: Green pigments index\", fontsize=9)\n",
    "axes[0,0].set_xlabel(col_x, fontsize=8)\n",
    "axes[0,0].set_ylabel(\"Frequency\", fontsize=8)\n",
    "\n",
    "# Boxplot for index\n",
    "axes[1,0].boxplot(df[col_x].dropna(), vert=True)\n",
    "axes[1,0].set_title(\"Boxplot: Green pigments index\", fontsize=9)\n",
    "axes[1,0].set_ylabel(col_x, fontsize=8)\n",
    "\n",
    "# Histogram for direct concentration\n",
    "axes[0,1].hist(df[col_y].dropna(), bins=20)\n",
    "axes[0,1].set_title(\"Histogram: Direct chlorophyll concentration (µg/g)\", fontsize=9)\n",
    "axes[0,1].set_xlabel(col_y, fontsize=8)\n",
    "axes[0,1].set_ylabel(\"Frequency\", fontsize=8)\n",
    "\n",
    "# Boxplot for direct concentration\n",
    "axes[1,1].boxplot(df[col_y].dropna(), vert=True)\n",
    "axes[1,1].set_title(\"Boxplot: Direct chlorophyll concentration (µg/g)\", fontsize=9)\n",
    "axes[1,1].set_ylabel(col_y, fontsize=8)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3fd7e2d-e362-4f60-a685-e95a9b9899df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Hypotheses\n",
    "# \n",
    "**H₀ (Null Hypothesis)**: The green pigment index and the direct chlorophyll concentration are not correlated.\n",
    "\n",
    "**H₁ (Alternative Hypothesis)**: There is a statistically significant correlation between the pigment index and the direct chlorophyll concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fab83d6-0541-4e8d-bc1f-c6255a11e49d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats# Drop missing values for the test\n",
    "\n",
    "df_clean = df.dropna(subset=[\n",
    "    \"green pigments: index\",\n",
    "    \"green pigments: direct concentration measurement (ug/g)\"\n",
    "])\n",
    "\n",
    "# Define variables\n",
    "x = df_clean[\"green pigments: index\"]\n",
    "y = df_clean[\"green pigments: direct concentration measurement (ug/g)\"]\n",
    "\n",
    "# Hypothesis test: Pearson correlation\n",
    "corr, p_value = stats.pearsonr(x, y)\n",
    "\n",
    "print(\"Pearson correlation coefficient:\", corr)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject H0: There is a significant correlation.\")\n",
    "else:\n",
    "    print(\"Fail to reject H0: No significant correlation.\")\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(x, y, alpha=0.7)\n",
    "plt.xlabel(\"index\")\n",
    "plt.ylabel(\"direct concentration measurement (µg/g)\")\n",
    "plt.title(\"Relationship between pigment index and direct concentration measurement\")\n",
    "\n",
    "# Add regression line\n",
    "slope, intercept, r_value, p_val, std_err = stats.linregress(x, y)\n",
    "plt.plot(x, slope*x + intercept, color=\"red\", label=f\"Linear fit (R²={r_value**2:.2f})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da9af8ba-0a3d-42ab-8244-e9d58e6b09e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Prepare data for statsmodels\n",
    "X = df_clean[\"green pigments: index\"]\n",
    "y = df_clean[\"green pigments: direct concentration measurement (ug/g)\"]\n",
    "X_with_const = sm.add_constant(X)\n",
    "\n",
    "# Fit OLS model\n",
    "model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "# Get influence measures\n",
    "influence = model.get_influence()\n",
    "leverage = influence.hat_matrix_diag\n",
    "residuals = influence.resid_studentized_internal\n",
    "cooks = influence.cooks_distance[0]  # Cook's distance\n",
    "\n",
    "# Thresholds for \"high\" leverage (commonly 2 * (p / n))\n",
    "p = X_with_const.shape[1]          # number of parameters (including intercept)\n",
    "n = len(df_clean)\n",
    "leverage_thresh = 2 * p / n\n",
    "\n",
    "# Plot residuals vs. leverage\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(leverage, residuals, alpha=0.7)\n",
    "ax.set_xlabel(\"Leverage\")\n",
    "ax.set_ylabel(\"Studentized Residuals\")\n",
    "ax.set_title(\"Residuals vs. Leverage\")\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Annotate points with high leverage (and optionally high Cook's distance)\n",
    "import random\n",
    "\n",
    "for i, (lev, res) in enumerate(zip(leverage, residuals)):\n",
    "    if lev > leverage_thresh:\n",
    "        row_idx = df_clean.index[i]\n",
    "        jitter_x = lev + np.random.uniform(-0.01, 0.01)\n",
    "        jitter_y = res + np.random.uniform(-0.1, 0.1)\n",
    "        ax.text(jitter_x, jitter_y, str(row_idx), fontsize=8, ha='right', va='bottom')\n",
    "for i, (lev, res) in enumerate(zip(leverage, residuals)):\n",
    "    if lev > leverage_thresh:\n",
    "        row_idx = df_clean.index[i]\n",
    "        ax.text(lev, res, str(row_idx), fontsize=8, ha='right', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4036f0ff-7812-47ad-afb1-f6cdc368c2ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "plt.style.use(\"seaborn-v0_8\") # pretty matplotlib plots\n",
    "\n",
    "def graph(formula, x_range, label=None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting cook's distance lines\n",
    "    \"\"\"\n",
    "    x = x_range\n",
    "    y = formula(x)\n",
    "    plt.plot(x, y, label=label, lw=1, ls='--', color='red')\n",
    "\n",
    "\n",
    "def diagnostic_plots(X, y, model_fit=None):\n",
    "  \"\"\"\n",
    "  Function to reproduce the 4 base plots of an OLS model in R.\n",
    "\n",
    "  ---\n",
    "  Inputs:\n",
    "\n",
    "  X: A numpy array or pandas dataframe of the features to use in building the linear regression model\n",
    "\n",
    "  y: A numpy array or pandas series/dataframe of the target variable of the linear regression model\n",
    "\n",
    "  model_fit [optional]: a statsmodel.api.OLS model after regressing y on X. If not provided, will be\n",
    "                        generated from X, y\n",
    "  \"\"\"\n",
    "\n",
    "  model_fit = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "\n",
    "  # create dataframe from X, y for easier plot handling\n",
    "  dataframe = pd.concat([X, y], axis=1)\n",
    "\n",
    "  # model values\n",
    "  model_fitted_y = model_fit.fittedvalues\n",
    "  # model residuals\n",
    "  model_residuals = model_fit.resid\n",
    "  # normalized residuals\n",
    "  model_norm_residuals = model_fit.get_influence().resid_studentized_internal\n",
    "  # absolute squared normalized residuals\n",
    "  model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "  # absolute residuals\n",
    "  model_abs_resid = np.abs(model_residuals)\n",
    "  # leverage, from statsmodels internals\n",
    "  model_leverage = model_fit.get_influence().hat_matrix_diag\n",
    "  # cook's distance, from statsmodels internals\n",
    "  model_cooks = model_fit.get_influence().cooks_distance[0]\n",
    "  tmp = pd.concat([model_fitted_y, model_residuals], axis=1, keys=['fitted', 'residuals'])\n",
    "\n",
    "\n",
    "  plot_lm_1 = plt.figure()\n",
    "  plot_lm_1.axes[0] = sns.residplot(data=tmp, x='fitted', y='residuals',\n",
    "                            lowess=True,\n",
    "                            scatter_kws={'alpha': 0.5},\n",
    "                            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "  plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "  plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "  plot_lm_1.axes[0].set_ylabel('Residuals');\n",
    "\n",
    "  # annotations\n",
    "  abs_resid = model_abs_resid.sort_values(ascending=False)\n",
    "\n",
    "  QQ = ProbPlot(model_norm_residuals)\n",
    "  plot_lm_2 = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
    "  plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "  plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "  plot_lm_2.axes[0].set_ylabel('Standardized Residuals');\n",
    "  # annotations\n",
    "  abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
    "\n",
    "  plot_lm_3 = plt.figure()\n",
    "  plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5);\n",
    "  tmp2 = pd.DataFrame(model_norm_residuals_abs_sqrt, columns = ['model_norm_residuals_abs_sqrt'])\n",
    "  tmp3 = pd.concat([model_fitted_y, tmp2], axis=1, keys=['fitted', 'residuals_normed'])\n",
    "  sns.regplot(data=tmp3, x='fitted', y='residuals_normed',\n",
    "                scatter=False,\n",
    "                ci=False,\n",
    "                lowess=True,\n",
    "                line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "  plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "  plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "  plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$');\n",
    "\n",
    "  # annotations\n",
    "  abs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt), 0)\n",
    "\n",
    "\n",
    "  plot_lm_4 = plt.figure();\n",
    "  plt.scatter(model_leverage, model_norm_residuals, alpha=0.5);\n",
    "  tmp4 = pd.DataFrame(model_leverage, columns = ['model_leverage'])\n",
    "  tmp5 = pd.DataFrame(model_norm_residuals, columns = ['model_norm_residuals'])\n",
    "  tmp6 = pd.concat([tmp4, tmp5], axis=1, keys=['leverage', 'residuals_normed'])\n",
    "  sns.regplot(data=tmp6, x='leverage', y='residuals_normed',\n",
    "             scatter=False,\n",
    "             ci=False,\n",
    "             lowess=True,\n",
    "              line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8});\n",
    "  plot_lm_4.axes[0].set_xlim(0, max(model_leverage)+0.01)\n",
    "  plot_lm_4.axes[0].set_ylim(-3, 5)\n",
    "  plot_lm_4.axes[0].set_title('Residuals vs Leverage')\n",
    "  plot_lm_4.axes[0].set_xlabel('Leverage')\n",
    "  plot_lm_4.axes[0].set_ylabel('Standardized Residuals');\n",
    "\n",
    "  # annotations\n",
    "  leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]\n",
    "  for i in leverage_top_3:\n",
    "      plot_lm_4.axes[0].annotate(i,\n",
    "                                 xy=(model_leverage[i],\n",
    "                                     model_norm_residuals[i]));\n",
    "\n",
    "  p = len(model_fit.params) # number of model parameters\n",
    "  graph(lambda x: np.sqrt((0.5 * p * (1 - x)) / x),\n",
    "        np.linspace(0.001, max(model_leverage), 50),\n",
    "        'Cook\\'s distance') # 0.5 line\n",
    "  graph(lambda x: np.sqrt((1 * p * (1 - x)) / x),\n",
    "        np.linspace(0.001, max(model_leverage), 50)) # 1 line\n",
    "  plot_lm_4.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb42dfe-0ae4-4f56-895d-7374a5448700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = df_clean[\"green pigments: index\"]\n",
    "y = df_clean[\"green pigments: direct concentration measurement (ug/g)\"]\n",
    "\n",
    "# Fit model to get leverage values and row indices\n",
    "import statsmodels.api as sm\n",
    "model_fit = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "influence = model_fit.get_influence()\n",
    "leverage = influence.hat_matrix_diag\n",
    "n = len(df_clean)\n",
    "p = 2  # intercept + 1 predictor\n",
    "leverage_thresh = 2 * p / n\n",
    "high_leverage_idx = np.where(leverage > leverage_thresh)[0]\n",
    "row_indices = df_clean.index.to_numpy()\n",
    "\n",
    "def diagnostic_plots_with_labels(X, y, model_fit, high_lev_idx, row_indices):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from statsmodels.graphics.gofplots import ProbPlot\n",
    "    import numpy as np\n",
    "    model_fitted_y = model_fit.fittedvalues\n",
    "    model_residuals = model_fit.resid\n",
    "    model_norm_residuals = model_fit.get_influence().resid_studentized_internal\n",
    "    model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "    model_leverage = model_fit.get_influence().hat_matrix_diag\n",
    "\n",
    "    # 1. Residuals vs Fitted\n",
    "    plt.figure()\n",
    "    sns.residplot(x=model_fitted_y, y=model_residuals, lowess=True,\n",
    "                  scatter_kws={'alpha': 0.5}, line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "    plt.title('Residuals vs Fitted')\n",
    "    plt.xlabel('Fitted values')\n",
    "    plt.ylabel('Residuals')\n",
    "    for i in high_lev_idx:\n",
    "        plt.annotate(str(row_indices[i]), (model_fitted_y.iloc[i], model_residuals.iloc[i]), fontsize=8, color='red')\n",
    "\n",
    "    # 2. Normal Q-Q\n",
    "    QQ = ProbPlot(model_norm_residuals)\n",
    "    fig = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
    "    plt.title('Normal Q-Q')\n",
    "    plt.xlabel('Theoretical Quantiles')\n",
    "    plt.ylabel('Standardized Residuals')\n",
    "    for i in high_lev_idx:\n",
    "        plt.annotate(str(row_indices[i]), (np.sort(QQ.theoretical_quantiles)[i], np.sort(model_norm_residuals)[i]), fontsize=8, color='red')\n",
    "\n",
    "    # 3. Scale-Location\n",
    "    plt.figure()\n",
    "    plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)\n",
    "    sns.regplot(x=model_fitted_y, y=model_norm_residuals_abs_sqrt, scatter=False, ci=False, lowess=True,\n",
    "                line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "    plt.title('Scale-Location')\n",
    "    plt.xlabel('Fitted values')\n",
    "    plt.ylabel('$\\sqrt{|Standardized Residuals|}$')\n",
    "    for i in high_lev_idx:\n",
    "        plt.annotate(str(row_indices[i]), (model_fitted_y.iloc[i], model_norm_residuals_abs_sqrt[i]), fontsize=8, color='red')\n",
    "\n",
    "    # 4. Residuals vs Leverage\n",
    "    plt.figure()\n",
    "    plt.scatter(model_leverage, model_norm_residuals, alpha=0.5)\n",
    "    sns.regplot(x=model_leverage, y=model_norm_residuals, scatter=False, ci=False, lowess=True,\n",
    "                line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "    plt.xlim(0, max(model_leverage)+0.01)\n",
    "    plt.ylim(-3, 5)\n",
    "    plt.title('Residuals vs Leverage')\n",
    "    plt.xlabel('Leverage')\n",
    "    plt.ylabel('Standardized Residuals')\n",
    "    for i in high_lev_idx:\n",
    "        plt.annotate(str(row_indices[i]), (model_leverage[i], model_norm_residuals[i]), fontsize=8, color='red')\n",
    "    # Cook's distance lines\n",
    "    def graph(formula, x_range, label=None):\n",
    "        x = x_range\n",
    "        y = formula(x)\n",
    "        plt.plot(x, y, label=label, lw=1, ls='--', color='red')\n",
    "    p = len(model_fit.params)\n",
    "    graph(lambda x: np.sqrt((0.5 * p * (1 - x)) / x),\n",
    "          np.linspace(0.001, max(model_leverage), 50),\n",
    "          'Cook\\'s distance')\n",
    "    graph(lambda x: np.sqrt((1 * p * (1 - x)) / x),\n",
    "          np.linspace(0.001, max(model_leverage), 50))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "diagnostic_plots_with_labels(X, y, model_fit, high_leverage_idx, row_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1060bfa3-9d6e-4441-a6ae-eb5e87250a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Log-transform y\n",
    "y_log = np.log(df_clean[\"green pigments: direct concentration measurement (ug/g)\"])\n",
    "\n",
    "# QQ plot for log-transformed y\n",
    "with plt.style.context(\"seaborn\"):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    stats.probplot(y_log, dist=\"norm\", plot=ax)\n",
    "    ax.set_title(\"QQ Plot (log-transformed y)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f92c22e-ff67-442e-ab02-7c7ce4643f04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Remove missing values and log-transform X, filter out inf/-inf after log\n",
    "df_model = df_clean.dropna(subset=[\"green pigments: direct concentration measurement (ug/g)\", \"organic carbon content in %\"]).copy()\n",
    "df_model[\"log_x\"] = np.log(df_model[\"green pigments: direct concentration measurement (ug/g)\"])\n",
    "df_model = df_model.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"log_x\", \"organic carbon content in %\"])\n",
    "\n",
    "# 1. Train/test split\n",
    "X = df_model[[\"log_x\"]]\n",
    "y = df_model[\"organic carbon content in %\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Evaluate metrics\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    \"RMSE_train\": mean_squared_error(y_train, y_train_pred, squared=False),\n",
    "    \"RMSE_test\": mean_squared_error(y_test, y_test_pred, squared=False),\n",
    "    \"MAE_train\": mean_absolute_error(y_train, y_train_pred),\n",
    "    \"MAE_test\": mean_absolute_error(y_test, y_test_pred),\n",
    "    \"R2_train\": r2_score(y_train, y_train_pred),\n",
    "    \"R2_test\": r2_score(y_test, y_test_pred)\n",
    "}\n",
    "print(metrics)\n",
    "\n",
    "# 4. Plot y vs predicted y for train and test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.7)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "axes[0].set_title(\"Train: Actual vs Predicted\")\n",
    "axes[0].set_xlabel(\"Actual y\")\n",
    "axes[0].set_ylabel(\"Predicted y\")\n",
    "\n",
    "axes[1].scatter(y_test, y_test_pred, alpha=0.7)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1].set_title(\"Test: Actual vs Predicted\")\n",
    "axes[1].set_xlabel(\"Actual y\")\n",
    "axes[1].set_ylabel(\"Predicted y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2682b24f-0265-4a3f-90ee-0259c415bad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Model Evaluation (English):**\n",
    "\n",
    "In my opinion, the model does not work properly. It always predicts a CO2 concentration of around 25%, regardless of the input. This is not realistic. In reality, CO2 concentrations above 50% were often observed. I am not surprised by this, because in reality, CO2 concentration is likely influenced by many more factors than just the pigment content. Therefore, in my view, the model is too simplistic."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01 - data reading, -cleaning  and description",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
