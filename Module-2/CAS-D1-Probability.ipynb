{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e4f116-e792-46dd-af10-6a0d8a7041a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Zc3eDfkC0qN7"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KGzB/CAS-Applied-Data-Science/blob/master/Module-2/CAS-D1-Probability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "719ff29a-d0ca-4274-a11f-fc5128d73506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VPrrXnuiCrxR"
   },
   "source": [
    "Notebook 2, Module 2, Statistical Inference for Data Science, CAS Applied Data Science, 2024-08-27, A. Mühlemann, University of Bern.\n",
    "\n",
    "*This notebook is based on the notebook by S. Haug and G. Conti from 2020*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "771be6ac-8514-4808-93ea-0450e307f5ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "AXe5g2m0CrxU"
   },
   "source": [
    "\n",
    "# 2. Probability and descriptive statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1331be12-3a38-4e2f-8669-342ef7efcd4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EC-udnfoCrxV"
   },
   "source": [
    "**Average expected study time :** 3x45 min (depending on your background). Your are supposed to play with the examples: change them, maybe test on another dataset. From just executing them, you will not learn much.\n",
    "\n",
    "**Learning outcomes :**\n",
    "- Random variables and probability density functions\n",
    "  - Know the normal probability density function (pdf)\n",
    "  - Know some other useful probability distributions\n",
    "- Describing data with descriptive statistics\n",
    "  - Obtain moments of a distribution. (mean, variance, standard deviation, kurtosis, skewness, quantile, median, mode)\n",
    "  - Generate data randomly according to a given distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d320db7e-d5be-4f51-b806-e9153e580f25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6vWrFVAvCrxW"
   },
   "outputs": [],
   "source": [
    "# Load the needed python libraries by executing this python code (press ctrl enter)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5786beb-28e3-456a-b4be-72e08618c9b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Xw0DzFIvCrxX"
   },
   "source": [
    "## 2.1 Random variables and probability density functions (pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1ea8051-8599-44db-a0ee-29bf518428c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ykLar845CrxX"
   },
   "source": [
    "As already mentioned this morning: probability theory is fundamental to statistics because it provides the mathematical framework for dealing with uncertainty and randomness, which are inherent in real-world data and phenomena.\n",
    "\n",
    "In inteferential statistics, we understand an experiment as a random process - similar to a coin toss - in which the outcome is unknown before it is conducted. With the help of probability theory, the possible outcomes can be described.\n",
    "\n",
    "Illustrated on our iris data set: we did not know which lenghts and widths we would obsereve, before we actually collected aour data. Thus, the data set at hand is the product of a random process. More precisely, for each flower the observed values are the outcome of a random process.\n",
    "\n",
    "Thus, the observables are often called **random variables** and denoted by $X$. All in all, we can view our dataset as a number of manifestations of random variables $X_1$, $X_2$,...., $X_n$.\n",
    "\n",
    "A random variable $X$ can be discrete or continuous. And they can be uniquely described by their distribution. One option to discribe their distribution, is to work with probablility mass functions (in the case of discrete $X$) and probability density functions (in the case of continuous $X$).\n",
    "\n",
    "If $X$ is discrete, then we use $f(x;\\theta)=P_\\theta(X=x)$ to denote the probability that random variable $X$ takes value $x$ (in python the term probability mass function, pmf, is used for $f(x;\\theta)$). The parameter $\\theta$ stands for the parameters that influence the shape of the probability mass function.\n",
    "\n",
    "If $X$ is a continuous random variable, then $X$ can be uniquely described by its probability density funtion (pdf) $f(x;\\theta)$ that may also depend on one or more parameters $\\theta$. In contrast to the case where $X$ is discrete, the values of $f(x;\\theta)$ cannot be directly interpreted as the probabilities of outcome $x$. Instead, we look at an interval $[a,b], a\\le b, $ and interpret the area that the density assumes in this interval as the probability that X takes a value between $a$ and $b$ i.e.\n",
    "\n",
    "$$\n",
    "\\int_a^b f(y,\\theta) \\, dy = P(X \\in [a,b]).\n",
    "$$\n",
    "\n",
    "\n",
    "The pdf is always normalized to **unity** (the number 1), i.e.\n",
    "$$\n",
    "\\int_{-\\infty}^\\infty f(y,\\theta) \\, dy = 1.\n",
    "$$\n",
    "This makes sense, as this means nothing else as that the probability that any of the possible outcomes materializes equals 1.\n",
    "\n",
    "Sometimes $\\theta$ is unknown. Then, we wish to estimate its value from a given set of measurements of $X_1, ..., X_n$. This is a central topic of statistics (see next notebook on parameter estimation and regression).\n",
    "\n",
    "The following sections introduce some of the most used distributions - first and foremost the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09472d47-9f27-41ed-a2e0-40f04c963de8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HLNrZDw8yCm1"
   },
   "source": [
    "### 2.1.1 The normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54420a25-98d6-40ce-8a5e-8f05e239bb24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1mwatAILCrxY"
   },
   "source": [
    "The normal (or Gaussian) distribution is probably the most used one. It\n",
    "derives its importance in large part from the *central limit theorem*. Roughly speaking the central limit theorem says \"In most situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a \"bell curve\") even if the original variables themselves are not normally distributed.\" https://en.wikipedia.org/wiki/Central_limit_theorem\n",
    "\n",
    "**Example:** If one flips a coin many times the probability of getting a given number of heads in a series of flips will approach a normal curve, with mean equal to half the total number of flips in each series. (In the limit of an infinite number of flips, it will equal a normal curve.)\n",
    "\n",
    "This means that in many cases it is sufficient to know the characteristics of the normal pdf. Also often unspecified statements like the *error*, or better, the *uncertainty* refer to their meaning on the normal pdf.\n",
    "\n",
    "The density of the normal distribution (in one dimension) is given by\n",
    "\n",
    "$$ f(x;\\mu,\\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp(\\frac{-(x-\\mu)^2}{2\\sigma^2}) $$\n",
    "\n",
    "It reads, given the distribution parameters mean $\\mu$ and variance $\\sigma$, x follows this function.\n",
    "\n",
    "### Exercise 2.1 (5 min)\n",
    "\n",
    "Plot the normal distribution with mean 0 and variance 5 for 400 x values between -20 to 20. Repeat this for two other means and variances. How big is the surface under the curves ?\n",
    "\n",
    "(See also scipy.stat.norm https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.norm.html)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96415e64-4d3c-40b4-8dcb-8ba30005db26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "yOp5o6mMCrxZ",
    "outputId": "aa76995d-8552-4485-8d9d-94d268ad50f0"
   },
   "outputs": [],
   "source": [
    "# Part of the solution:\n",
    "x = np.linspace(-20,20,400) # 400 bins from -20 to 20\n",
    "plt.plot(x, scipy.stats.norm.pdf(x,0,5**0.5))\n",
    "plt.plot(x, scipy.stats.norm.pdf(x,0,2**0.5))\n",
    "plt.legend(['sigma=5', 'sigma=2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e957443-510d-413a-a900-96955f07e06a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "kFwri6PS0LS7"
   },
   "source": [
    "### 2.1.2 Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c135ca27-0b7e-472f-a2de-81678c729ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "KENC1KioCrxh"
   },
   "source": [
    "**Some words on the Poisson distribution**\n",
    "\n",
    "The Poisson distribution is popular for modelling the number of times an event occurs in an interval of time or space. For example:\n",
    "\n",
    "- The number of meteorites greater than 1 meter diameter that strike earth in a year\n",
    "- The number of patients arriving in an emergency room between 10 and 11 pm\n",
    "\n",
    "The probability mass function is $$f(k;\\lambda) = \\frac{\\lambda^k exp(-\\lambda)}{k!}$$\n",
    "For large $k$ the normal distribution is an excellent approximation of the poisson pdf. For $k$ below 20 one should be careful using statements based on the normal distribution, e.g. the distribution is not symmetric anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5601628-a266-4d8b-845a-afb9b7de497f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "d0Zhw0nGCrxh",
    "outputId": "75a0945f-21c2-4674-f11f-d358c7dc9df1"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-1, 40)\n",
    "plt.step(x,scipy.stats.poisson.pmf(x,2))\n",
    "plt.step(x,scipy.stats.poisson.pmf(x,15))\n",
    "plt.legend(['lambda=2', 'lambda=15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cd98f01-4aae-42ce-9249-c433c9416347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Dn2EbwxYCrxh"
   },
   "source": [
    "We see that a possion pdf with mean 15 looks very much like the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2a3854a-26b9-4c24-81a2-18c2f2d0cf47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "aH24nsOg0zRr"
   },
   "source": [
    "#### Exercise (after reading the section on descriptive statistics)\n",
    "Get some desciptive statistics from the poisson pmf with mean 1.7. See also https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07344450-a51f-4ed8-9967-04fbb65a8257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhgpz6OgCrxg",
    "outputId": "9e4b6db2-fca0-4942-feca-98b0b0471cae"
   },
   "outputs": [],
   "source": [
    "mean, variance, skewness, kurtosis = scipy.stats.poisson.stats(1.7,moments='mvsk')\n",
    "#my_norm = norm(0,2)\n",
    "print('Mean = %1.2f Var = %1.2f Std = %1.2f Skewness = %1.2f kurtosis = %1.2f' % (mean,variance,variance**0.5,skewness,kurtosis))\n",
    "#my_norm.moments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cabf6d46-8b20-486b-9ef6-81c51a973334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Cg54iLV-Crxg"
   },
   "source": [
    "Plot mode and median of the above poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23c4218c-6b96-44be-b562-962aa2466cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "Wk9FOtnrCrxg",
    "outputId": "cbf49c70-09b0-4a2c-ce93-571c22bef0cb"
   },
   "outputs": [],
   "source": [
    "dist = scipy.stats.poisson(1.7)\n",
    "x = np.arange(-1, 10)\n",
    "sigma=variance**0.5\n",
    "plt.step(x,dist.pmf(x))\n",
    "dist.median()\n",
    "plt.axvline(x=mean, linewidth=2, color = 'k',label=\"Mean\")\n",
    "plt.axvline(x=mean+sigma, linewidth=2, color = 'r', label=\"Sigma (standard deviation)\")\n",
    "plt.axvline(x=dist.median(), linewidth=2, color = 'b',label=\"Median\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ae8c972-4a58-486c-a126-4333255ca2b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WTZQ-K0eCrxh"
   },
   "source": [
    "### 2.1.3 Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b282ba6d-c8e2-4adc-b84c-5a4013796340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1AmdW0mZCrxh"
   },
   "source": [
    "The binomial distribution is frequently used to model the number of successes $k$ in a sequence of $n$ independent experiments.\n",
    "\n",
    "$$f(k;n,p) = \\binom{n}{k} \\cdot p^kq^{n-k}$$\n",
    "\n",
    "The binomial distribution converges towards the Poisson distribution as the number of trials $n$ goes to infinity while the product $np_n$ remains fixed. In this case, the Poisson distribution with parameter $\\lambda = np$ can be used as an approximation of the binomial distribution with parameters $n$ and $p$.\n",
    "\n",
    "For $n>20$ and $p$ not too close to $1$ or $0$, the normal distribution is also here a good approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33607b1b-2408-4609-aab9-d1e563bc2c05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "kwu7F1Z4Crxi",
    "outputId": "28cd0db8-f992-4392-dde0-92e78f8a3c2c"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-1, 40)\n",
    "plt.step(x,scipy.stats.binom.pmf(x,40,0.05))\n",
    "plt.step(x,scipy.stats.binom.pmf(x,40,0.2))\n",
    "plt.step(x,scipy.stats.binom.pmf(x,40,0.5))\n",
    "plt.step(x,scipy.stats.binom.pmf(x,40,0.8))\n",
    "plt.legend(['n=40, p=0.05', 'n=40, p=0.2', 'n=40, p=0.5', 'n=40, p=0.8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3538c8-8975-4196-abb7-74275085f953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "sn-zV5dL11kA"
   },
   "source": [
    "### 2.1.4 Student-distribution or t-distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b26265f-bfa6-4a91-89f2-d7c89a494476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PkE4TeRCCN1C"
   },
   "source": [
    "The $t$-distribution is symmetric and bell-shaped, like the normal distribution. However, the $t$-distribution has heavier tails than the normal distribution. This means that it is more prone to producing values that fall far from its mean. This makes it useful for understanding the statistical behavior of certain types of ratios of random quantities, in which variation in the denominator is amplified and may produce outlying values when the denominator of the ratio falls close to zero.\n",
    "\n",
    "\n",
    "We will indirectly encounter the $t$-distribution on day four, when we look at hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98d48e07-2868-4032-b7fa-47965ad0d3d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEwcdhYg2nqW",
    "outputId": "76beee40-7833-4eb2-f838-da8bfdf2e96c"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "df=8\n",
    "mean, var, skew, kurt = t.stats(df, moments='mvsk')\n",
    "print('Mean = %1.2f Var = %1.2f Std = %1.2f Skewness = %1.2f kurtosis = %1.2f' % (mean,var,var**0.5,skew,kurt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d75a47c1-b9bf-484e-b913-037b97eb6d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3fBVK7bL4KyT"
   },
   "source": [
    "Plot the pdf for 2 and 10 degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3a9e265-bd3c-4cea-97b6-4c0aa183b191",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "8AlgX6A34N3K",
    "outputId": "4c6e3e6b-95ea-4ee7-a151-26a014b5e4aa"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "df=2\n",
    "x = np.linspace(t.ppf(0.01, df),\n",
    "                t.ppf(0.99, df), 100)\n",
    "ax.plot(x, t.pdf(x, df),\n",
    "        'r-', lw=2, alpha=0.6, label='t pdf')\n",
    "\n",
    "df=10\n",
    "x = np.linspace(t.ppf(0.01, df),\n",
    "                t.ppf(0.99, df), 100)\n",
    "ax.plot(x, t.pdf(x, df),\n",
    "        'b-', lw=2, alpha=0.6, label='t pdf')\n",
    "ax.legend(['df=2','df=10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bb6b3d2-1c3e-4671-8ac8-b7c2a879bb62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VdtG6mWF5Pen"
   },
   "source": [
    "### 2.1.5 Gamma distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a679dae-6b37-4205-86bf-009b2c204e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9K6_rgOWCS3k"
   },
   "source": [
    "In probability theory and statistics, the gamma distribution is a two-parameter family of continuous probability distributions.\n",
    "\n",
    "The depending on the parameters the Gamma distribution can be skewed to that it can be helpful to model the size of insurance claims and rainfalls.\n",
    "\n",
    "Lets look at the gamma pdf for different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c31f0b3a-bac2-44b1-b1c8-ee5206125f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "2M7wJtms6wmH",
    "outputId": "66254166-36c2-46f6-f4ae-1e8964fb6c84"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "a = 2\n",
    "x = np.linspace(gamma.ppf(0.01, a),\n",
    "                gamma.ppf(0.99, a), 100)\n",
    "\n",
    "ax.plot(x, gamma.pdf(x, a),\n",
    "       'r-', lw=2, alpha=0.6, label='gamma pdf')\n",
    "\n",
    "a = 4\n",
    "x = np.linspace(gamma.ppf(0.01, a),\n",
    "                gamma.ppf(0.99, a), 100)\n",
    "\n",
    "ax.plot(x, gamma.pdf(x, a),\n",
    "       'b-', lw=2, alpha=0.6, label='gamma pdf')\n",
    "a = 8\n",
    "x = np.linspace(gamma.ppf(0.01, a),\n",
    "                gamma.ppf(0.99, a), 100)\n",
    "\n",
    "ax.plot(x, gamma.pdf(x, a),\n",
    "       'g-', lw=2, alpha=0.6, label='gamma pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58bcda1b-d789-441b-bf56-622d2420f228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wn1aQWsuAMAA"
   },
   "source": [
    "Of course there are many many more useful distribution. If you want to see more, check out this reference http://staff.fysik.su.se/~walck/suf9601.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a90527f6-3634-4de5-b57f-cb0a9f1d35d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fK-auKXeCrxc"
   },
   "source": [
    "## 2.2 Describing distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dfbe477-7848-4753-b862-dd9d62e6cacd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2GaZl2ICx20_"
   },
   "source": [
    "### 2.3.1 Moments of the pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f615ba71-67d1-4ac8-bb30-a7d0b1762b68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iR9Hd4wCCrxc"
   },
   "source": [
    "\n",
    "An important operator often used in probability theory and statistics is the expectation of a random variable $X$ with pdf $f(x;\\theta)$ given by\n",
    "$$\\mu=\\mathbb{E}(X) = \\int_{-\\infty}^{\\infty} xf(x; \\theta)dx.   $$\n",
    "The expected value is basically a generalized weighted average. In the case where $X$ is discrete the expectation is given by\n",
    "In the discrete case this integral becomes the sum known as the arithemtic mean:\n",
    "$$ \\mu = \\mathbb{E}(X)=  \\sum_{i=1}^n \\mathbb{P}(X=x_i) x_i.$$\n",
    "If $X$ is uniform this reduces to\n",
    "$$ \\mu=\\mathbb{E}(X) = \\frac{1}{n}\\sum_{i=1}^n  x_i.$$\n",
    "\n",
    "Since in statistics we assume that our draws are uniform this is the formula we use to estimate the expectation.\n",
    "<!--\n",
    "and the $n^{th}$ central moment of x (or moment about the mean, $α_1$) is\n",
    "\n",
    "$$ m_n \\equiv E[(x-\\alpha_1)^n] = \\int_{-\\infty}^{\\infty} (x-\\alpha_1)^nf(x)dx   $$\n",
    "-->\n",
    "\n",
    "Another operator closely related to the **mean $\\mu$ (or expectated value)** is the **variance $\\sigma^2$**, that is the expectation of the squared deviation of a random variable from its mean:\n",
    "\n",
    "$$\\sigma^2= Var(X) =\\int_{-\\infty}^{\\infty} (x-\\mu)^2 f(x)dx$$\n",
    "\n",
    "If $X$ is discrete then\n",
    "$$ \\sigma^2 = Var(X)=\\sum_{i=1}^n (x_i - \\mu)^2P(X=x_i).$$\n",
    "\n",
    "If $X$ is uniform this reduces to\n",
    "$$ \\sigma^2 = Var(X)= \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2.$$\n",
    "\n",
    "The mean is the location of the “center of mass” of the pdf, and the variance is a measure of the square of its width. It is often convenient to use the **standard deviation (SD)** of $X$, $\\sigma$, defined as the square root of the variance.\n",
    "\n",
    "The mean and variance are especially important when talking about normal distribution as they uniquely characterize the graph of the normal distribution:  the mean is center of the graph and the standard deviation  determines the amount of dispersion away from the mean.\n",
    "\n",
    "The idea behind the mean can be generalized, so that we obtain a the notion of moments\n",
    "$$\\mathbb{E}(x^n) = \\int_{-\\infty}^{\\infty} x^nf(x)dx.   $$\n",
    "\n",
    "The second moment $\\mathbb{E}(X^2)$ occurs in the variance, the third $\\mathbb{E}(X^3)$ is related to the skewness and fourth moment $\\mathbb{E}(X^4)$ to the kurtosis.  The skewness is a number indicating the deviation from a symmetric form. Kurtosis is a number indicating if the tails of the distribution is larger or smaller then the tails of the normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "649e56a1-2ea5-4748-bb7d-6d975306add9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qCzAPTnbCrxd"
   },
   "source": [
    "### 2.3.2 Quantiles and median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5212d55-c286-4cee-9c64-eb063db92f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qJO3-Bk6Crxd"
   },
   "source": [
    "The **quantile $q_{\\alpha}$** is the value $x$ of the random variable $X$ at which $\\alpha\\%$ of the area is smaller than $x$. An important special case is the **median, $q_{med} \\equiv q_{0.5}$**. At the median half the area lies above and half lies below.\n",
    "For the normal pdf the median equals the mean. The most probable value of a distribution is called **mode**.\n",
    "\n",
    "Special quantiles are the quartiles and percentiles. The first quartile is the $q_{0.25}$, the second the $q_{0.5}$ etc. Percentiles are for example $q_{0.75}$ etc.\n",
    "\n",
    "<!--\n",
    "Any odd moment about the mean is a measure of the **skewness** of the p.d.f. The simplest of these is the dimensionless coefficient of skewness $\\gamma_1 = m_33/\\sigma^3$.\n",
    "\n",
    "The fourth central moment $m_4$ provides a convenient measure of the tails of a distribution. For the Gaussian distribution, one has $m_4 = 3\\sigma^4$. The **kurtosis** is defined as $\\gamma_2 = m_4/\\sigma^4 − 3$, i.e., it is zero for a Gaussian, positive for a leptokurtic distribution with longer tails, and negative for a platykurtic distribution with tails that die off more quickly than those of a Gaussian.\n",
    "\n",
    "The **quantile $x_{\\alpha}$** is the value of the random variable x at which the cumulative distribution is equal to $\\alpha$. That is, the quantile is the inverse of the cumulative distribution function, i.e., $x_{alpha} = F^{−1}(\\alpha)$. An important special case is the **median, $x_{med}$**, defined by $F(x_{med}) = 1/2$, i.e., half the probability lies above and half lies below $x_{med}$. (More rigorously, $x_{med}$ is a median if $P(x \\geq x_{med}) \\geq 1/2$ and $P(x \\leq x_{med}) \\geq 1/2$. If only one value exists, it is called ‘the median.’)\n",
    "\n",
    "Under a monotonic change of variable $x \\rightarrow y(x)$, the quantiles of a distribution (and hence also the median) obey $y_{\\alpha} = y(x_{\\alpha})$. In general the expectation value and **mode** (most probable value) of a distribution do not, however, transform in this way.\n",
    "\n",
    "Let us look at median and quantile$_68$ of the normal pdf:\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fd7c5b8-64bd-4563-a80b-98dceae936f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qCwS2yugCrxe"
   },
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "183938a5-4556-4389-87a0-c3f5aeaaca2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "h2KRFefuCrxe"
   },
   "source": [
    "Get some desciptive statistics from a normal (continous) pdf with mean 0 and standard deviation 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4da18951-df18-481b-95f6-0e78788f2373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8O9HCdPCrxe",
    "outputId": "d57488af-9e1c-43c5-efd6-af95592d95af"
   },
   "outputs": [],
   "source": [
    "mean, variance, skewness, kurtosis = scipy.stats.norm.stats(0,4,moments='mvsk')\n",
    "print(mean, variance, skewness, kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca0a622a-7001-49b6-bf78-7a1cfd417068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "P1zQ_0IPCrxf"
   },
   "source": [
    "Plot the pdf and some moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02abbde9-c461-410b-9cb1-a1fe48d9b6be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "xM0X1SedCrxf",
    "outputId": "a7daa653-fde5-498b-91f8-000b962edf31"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-20,20,400)\n",
    "sigma=variance**0.5\n",
    "plt.plot(x,scipy.stats.norm.pdf(x,mean,sigma))\n",
    "plt.axvline(x=mean, linewidth=2, color = 'k',label=\"Mean\") # Plot the mean as a vertical line\n",
    "plt.axvline(x=mean-sigma, linewidth=2, color = 'r', label=\"Sigma (standard deviation)\")\n",
    "plt.axvline(x=mean+sigma, linewidth=2, color = 'r')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e529137e-66f8-485b-9266-4a0031f8734a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fOlh90B0Crxj"
   },
   "source": [
    "Produce the descriptive statistics for the Iris Virginica data.\n",
    "Then plot the histograms and scatter plots.\n",
    "We have seen that Iris Virginica could possibly be normal distributied. Thus, median and mean should be close. Let us check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87160f0e-8cdd-45c7-8e67-b81e64d39e7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "efAFpQ3pCrxj",
    "outputId": "2144510f-7b2f-4f9c-be6e-377d0c17d669"
   },
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "dataframe = pd.read_csv(url,names=['slength','swidth','plength','pwidth','species'])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44e85093-fbc9-49f2-901d-25ee9e2b79ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "ArKI8jH_Crxk",
    "outputId": "b87010a2-9baa-48f8-d874-20d4e8c4c731"
   },
   "outputs": [],
   "source": [
    "df_virginica = dataframe[dataframe['species']=='Iris-virginica']\n",
    "df_virginica.drop(columns=['species']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6adcec27-97ef-49c1-8b6b-d4f565d6892a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "A_zFdBALCrxk",
    "outputId": "64f8eb6a-9a6f-4109-87f9-8869992c794f"
   },
   "outputs": [],
   "source": [
    "df_virginica.drop(columns=['species']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1968ee09-1d69-4805-9417-be4207bf0abd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "VYosdtrLCrxk",
    "outputId": "ce1992f3-0036-4080-d66c-c9b007f5c698"
   },
   "outputs": [],
   "source": [
    "df_virginica.drop(columns=['species']).describe() # Or get a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "702d6ed1-8393-4886-bfa9-659bf54350e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VPsjBML9Crxk"
   },
   "source": [
    "All the descriptive statistics methods for python dataframes are listed here:\n",
    "https://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f107e59-4d87-4f83-a189-2faae22f141b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jLHDhA6dCrxl"
   },
   "source": [
    "Now we looked at the numbers. Let's us plot the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f77f22c2-437b-4f3a-b91b-e3767386becc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "meWumlBECrxl",
    "outputId": "7b7647a7-a6b6-4c91-dc1d-717bb1a51642"
   },
   "outputs": [],
   "source": [
    "df_virginica['slength'].plot(kind=\"hist\",fill=False,histtype='step',title='Iris Setosa', label=\"length\")\n",
    "ax = df_virginica['swidth'].plot(kind=\"hist\",fill=False,histtype='step', label=\"width\")\n",
    "ax.set_xlabel('Setal length/width [cm]')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01bc567f-c47a-4a4f-a4a7-2a050d2f9c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "KZXVT141Crxn"
   },
   "source": [
    "## 2.4 How to generate random variables based on a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b73b9b15-c72c-4111-acf4-6f4bd481a2db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9Br53E6bCrxn"
   },
   "source": [
    "One can simulate data sets by generating them from probability density functions. The computer does this with a so called Monte Carlo (MC) algorithm. It draws $x$ values (pseudo) randomly from the given distribution. The the actual draws of the random variable are called random variates. Simulations can be very useful when planning an experiment and developing the analysis method. Instead of real data one can use the simulated data.\n",
    "\n",
    "Let us simulate the iris virginica sepal width data (width the mean and standard deviation we got from the real data) given that a normal distribution is a reasonable model for the swith of iris virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b49c4ac5-8f6d-4d21-8748-f6a3abf4312c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "la2x-Bj1Crxn"
   },
   "outputs": [],
   "source": [
    "n = scipy.stats.norm.rvs(2.974000,0.322497,50) # 100 random values from a normal distribution with mean 2.974000 and SD 0.322497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd3b4c26-9f71-4d09-a132-677f67f0f5f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QQ-hi0XCrxn",
    "outputId": "e8d0446c-c2b9-4547-d15f-8b4b4aaf9044"
   },
   "outputs": [],
   "source": [
    "print(n[0:10]) # Print first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fa6fb64-23ef-455a-b3ec-29c0de906b80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tOtk5NC_Crxo",
    "outputId": "6a97a02f-eff4-4d63-b74d-67ea0cda4894"
   },
   "outputs": [],
   "source": [
    "# Put the simulated data into a dataframe\n",
    "df_virginica_sim = pd.DataFrame(n)\n",
    "df_virginica_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58848b8d-b6f1-4a5c-bfdf-97f5d7e165ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fo9ii-BTzfMH"
   },
   "source": [
    "####Exercise\n",
    "Try to generate a random t-distributed sample of size 20 with df=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27a9c464-57c3-40ad-8ec8-bc709c067188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LJbew-Lez6Xa"
   },
   "outputs": [],
   "source": [
    "## write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8ec1bea-4cf7-4433-a90d-3a24139b2c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WOGKZWDrCrxp"
   },
   "source": [
    "## 2.5 Uncertainties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96c5e25b-5064-4e47-ae50-a24e8631ee6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "zVZCEv6LCrxp"
   },
   "source": [
    "All data have uncertainties. These should always be communicated when showing scientific numbers or plots. We distinguish between two types.\n",
    "\n",
    "- Statistical uncertainties\n",
    "    - Fluctuations, can be made smaller by taking more data, i.e. get more statistics\n",
    "- Systematic uncertainties\n",
    "    - Shift of data in one direction due to some \"mistake\" in the measurement, e.g. wrongly calibrated instrument showing all measured values systematically higher as they really are. Or for instance uncertainty due to the choice of methods and tools\n",
    "    \n",
    "The statistics tools can mostly handle the statistical uncertainties. There is no mathematical recipe for dealing with systematical uncertainties. You have to think through your experiment and try to estimate the influence of everything that can go wrong.\n",
    "\n",
    "When uncertainties are stated on numbers or in graphs as error bars or error bands they generally show one standard deviation. If the data are well described by a normal distribution, the interpretation of one standard deviation is clear: if the measurement is repeated many times, 32% (or about 1/3 of the measurements) **should** be outside the error bars.\n",
    "\n",
    "If the distribution is not normal, the interpretation of one standard deviation is not as clear. For example, a poisson distribution is not necessary symmetric. So again we see, for low counts where the normal asumption is not a good approximation, let's say below 20, the interpretation is not obvious anymore and care is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b39f3e12-7146-4d61-a670-1e64ffcfb6d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "CGtcz0trCrxq",
    "outputId": "f58820ef-dd9d-4f0a-8067-962a9c2cb267"
   },
   "outputs": [],
   "source": [
    "# Draw a histogram which is not normalised\n",
    "entries1, edges, patches = plt.hist(n, bins=10, histtype='step')\n",
    "# Close plt so that this histogram is not shown\n",
    "plt.close()\n",
    "# Draw a histogram which IS normed\n",
    "entries2, edges, patches = plt.hist(n, bins=10, histtype='step',density=True)\n",
    "# Calculate the poisson standard deviation and scale down to second histogram\n",
    "errors = np.sqrt(entries1) * entries2/entries1\n",
    "# calculate bin centers\n",
    "bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "# draw errobars, use the sqrt error.\n",
    "plt.errorbar(bin_centers, entries2, yerr=errors, fmt='r.')\n",
    "# Draw a normal distribution\n",
    "x = np.linspace(2.4,4.2,100)\n",
    "sigma=variance**0.5\n",
    "plt.plot(x,scipy.stats.norm.pdf(x,df_virginica_sim.mean(),df_virginica_sim.std()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff57dc51-c05b-4adc-8383-f3e483e17ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "98Ov7KLYCrxq"
   },
   "source": [
    "We see that 3 out of 10 data points are more than one standard deviation off the \"theory\" curve. This is how it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6e9dda5-5b35-4874-a5bf-88a3c7eb4724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YSQjhejaCrxq"
   },
   "source": [
    "## 2.6 Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a91df124-90d0-4dad-8075-85c9d4f2e717",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fAP80BACCrxr"
   },
   "source": [
    "Do you have a question for tomorrow's discussion session: https://forms.gle/QUL62MbmQiEEYvY37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25badcc6-de8c-49ca-a8b2-19d766308d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2lsdO0c2Crxr"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16da5f58-33c4-4f2a-8ce3-c8668957d49b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "to2UjCSXCrxr"
   },
   "source": [
    "1. H. Cramer, Mathematical Methods of Statistics, (Princeton Univ. Press, New Jersey, 1958).\n",
    "2. A. Stuart and J.K. Ord, Kendall’s Advanced Theory of Statistics, Vol. 1 Distribution Theory 6th Ed., (Halsted Press, New York, 1994), and earlier editions by Kendall and Stuart.\n",
    "3. R.J. Barlow, Statistics: A Guide to the Use of Statistical Methods in the Physical Sciences, (John Wiley, New York, 1989).\n",
    "4. S. Brandt, Data Analysis, 3rd Ed., (Springer, New York, 1999).\n",
    "5. G. Cowan, Statistical Data Analysis, (Oxford University Press, Oxford, 1998).\n",
    "6. A.N. Kolmogorov, Grundbegriffe der Wahrscheinlichkeitsrechnung, (Springer, Berlin,\n",
    "1933); Foundations of the Theory of Probability, 2nd Ed., (Chelsea, New York 1956).\n",
    "7. Ch. Walck, Hand-book on Statistical Distributions for Experimentalists, University of Stockholm Internal Report SUF-PFY/96-01, available from http://staff.fysik.su.se/~walck/suf9601.pdf.\n",
    "8. M. Abramowitz and I. Stegun, eds., Handbook of Mathematical Functions, (Dover, New York, 1972)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d00cf947-9c2a-4219-8973-b41e385b25ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "E7Jypp7CClEI"
   },
   "source": [
    "# Annex Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3290e77e-6e72-4079-ba69-342eff050816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_a6zps4YCrxr"
   },
   "source": [
    "An abstract definition of probability can be given by considering a set $\\Omega$, called the sample space, and possible subsets $A,B,...$ the interpretation of which is left open. The probability $P$ is a real-valued function defined by the following axioms due to Kolmogorov (1933) [9]:\n",
    "\n",
    "- For every subset $A$ in $S$, $P(A) ≥ 0$;\n",
    "- For disjoint subsets (i.e., $A ∩ B = ∅$), $P(A ∪ B) = P(A) + P(B)$;\n",
    "- $P(S)=1$.\n",
    "\n",
    "From this further properties can be derives, e.g.\n",
    "\n",
    "- $P(\\bar{A}) = 1 - P(A)$\n",
    "- $P(A \\cup \\bar{A}) = 1$\n",
    "- $P(\\emptyset) = 0$\n",
    "- if A in B, then $P(A)\\leq P(B)$\n",
    "- $P(A \\cup \\bar{A}) = P(A) + P(B) - P(A\\cap B)$\n",
    "\n",
    "#### Conditional probability\n",
    "In addition, one defines the conditional probability $P(A|B)$ (read as $P$ of $A$ given $B$) as $$P(A|B) = \\frac{P(A ∩ B)}{P(B)}$$\n",
    "\n",
    "As an example, when throwing the dice, consider obtaining more than 3 eyes given only trows with even number of eyes outcomes. We calculate the (conditional) probability:\n",
    "\n",
    "$$P(n>3|n\\; even) = \\frac{P(n>3 \\cap n\\; even)}{P(even)} = \\frac{2/6}{3/6} = \\frac{2}{3}$$\n",
    "\n",
    "#### Independence\n",
    "\n",
    "If A and B are independent, then\n",
    "\n",
    "$$P(A|B) = \\frac{P(A ∩ B)}{P(B)} = \\frac{P(A)P(B)}{P(B)} = P(A)$$\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "CAS-D1-Probability",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
