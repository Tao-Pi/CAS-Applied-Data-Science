{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f6535d2-d9d7-4b03-aa21-daead58f9ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neworldemancer/DSF5/blob/master/Course_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "229e2a65-72fa-46c3-91d1-cfcaff3b9796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Introduction to machine learning & Data Analysis\n",
    "\n",
    "Basic introduction on how to perform typical machine learning tasks with Python.\n",
    "\n",
    "Prepared by Mykhailo Vladymyrov & Aris Marcolongo,\n",
    "Data Science Lab, University Of Bern, 2023\n",
    "\n",
    "This work is licensed under <a href=\"https://creativecommons.org/share-your-work/public-domain/cc0/\">CC0</a>.\n",
    "\n",
    "# Part 2: Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9892d5bd-4ae8-4f13-8762-fbae0af3fa35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b-fYVr8NTLeK"
   },
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T14:05:44.613282Z",
     "start_time": "2022-09-27T14:05:43.538999Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da0da146-873b-48cd-8976-49e29183f002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hVJn0ilgOS8F",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import  pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "\n",
    "from time import time as timer\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import tensorflow as tf\n",
    "import tarfile\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a84128e0-3134-4430-8b33-6336884b957e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zV3YwuW4L6Yy",
    "outputId": "b067b97a-6cb6-4c47-f07b-83586d5844a8"
   },
   "outputs": [],
   "source": [
    "pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T14:05:49.051625Z",
     "start_time": "2022-09-27T14:05:46.022444Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2263cb9-4526-4c8e-af3b-8e0751d827d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oes8tZkKXS1S"
   },
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T14:05:50.662474Z",
     "start_time": "2022-09-27T14:05:50.657850Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f75a290-d7be-4b1d-8a37-2a1c8c5c1a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xQIE54NmqJs",
    "outputId": "b816a504-e059-401f-8b4f-176be800ad71"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tarfile\n",
    "import os\n",
    "from packaging import version\n",
    "import shutil\n",
    "import sys \n",
    "\n",
    "def download_and_extract_data(\n",
    "    url=\"https://github.com/neworldemancer/DSF5/raw/master/colab_material.tgz\",\n",
    "    target_dir=\"data\",\n",
    "    fname=\"colab_material.tgz\",\n",
    "    update_folder=False\n",
    "):\n",
    "    \"\"\"Download and extract a tar.gz dataset into target_dir.\"\"\"\n",
    "    \n",
    "    if update_folder and os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        cache_dir = os.path.abspath(\".\")\n",
    "\n",
    "        if version.parse(tf.__version__) >= version.parse(\"2.13.0\"):\n",
    "            # new behavior: fname must be only a filename\n",
    "            path = tf.keras.utils.get_file(\n",
    "                fname=fname,\n",
    "                origin=url,\n",
    "                cache_dir=cache_dir\n",
    "            )\n",
    "        else:\n",
    "            # old behavior: can pass full path\n",
    "            path = tf.keras.utils.get_file(\n",
    "                fname=os.path.join(cache_dir, fname),\n",
    "                origin=url\n",
    "            )\n",
    "        # extract tar into target_dir\n",
    "        with tarfile.open(path, \"r:gz\") as tar:\n",
    "            tar.extractall(target_dir)\n",
    "    else:\n",
    "        print('Data already present. Use update_folder = True to overwrite/update if desired.')\n",
    "    return os.path.abspath(target_dir)\n",
    "\n",
    "data_path = download_and_extract_data(update_folder=False)\n",
    "sys.path.append(data_path)\n",
    "print(\"Data available at:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T19:22:00.451788Z",
     "start_time": "2022-09-26T19:22:00.401516Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8816963-aa1c-4e7f-8b1e-9d23cc21d224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "atch-QcelhRy"
   },
   "outputs": [],
   "source": [
    "from utils.routines import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4c6bae6-7083-47f0-ae10-5b89554ee012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cBxkWZaLCUcR"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebf5179d-7499-48fb-acb6-33ec0659a052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4MssLYOiCUcX"
   },
   "source": [
    "In this course we will use several synthetic and real-world datasets to illustrate the behavior of the models and exercise our skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26489313-58b4-4e07-906d-264ce7edf783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8UQgU5I-lEll"
   },
   "source": [
    "## 1. Synthetic linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2067f6fc-e66a-4305-833c-19c8f7f3b69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jGfWOWRjlWPa"
   },
   "outputs": [],
   "source": [
    "def get_linear(n_d=1, n_points=10, w=None, b=None, sigma=5):\n",
    "  x = np.random.uniform(0, 10, size=(n_points, n_d))\n",
    "\n",
    "  w = w or np.random.uniform(0.1, 10, n_d)\n",
    "  b = b or np.random.uniform(-10, 10)\n",
    "  y = np.dot(x, w) + b + np.random.normal(0, sigma, size=n_points)\n",
    "\n",
    "  print('true slopes: w =', w, ';  b =', b)\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7079d5c-a480-4b9f-aee7-81d4bda06115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5RLYxGy_nBZG"
   },
   "outputs": [],
   "source": [
    "x, y = get_linear(n_d=1, sigma=0)\n",
    "plt.plot(x[:, 0], y, '*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "720a6ba1-5770-4a70-996c-4fae2ea031c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "10ODDOp4nX4S"
   },
   "outputs": [],
   "source": [
    "n_d = 2\n",
    "x, y = get_linear(n_d=n_d, n_points=100)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], y, marker='x', color='b',s=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad489291-513e-4d87-aabe-0d9e0e284ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-2uMw5C4CUcj"
   },
   "source": [
    "## 2. House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5daa13f3-38f6-4190-8239-5f4933a12d4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qi_Q6YTNCUcj"
   },
   "source": [
    "Subset of the Ames Houses dataset: http://jse.amstat.org/v19n3/decock.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36790e61-bebb-4e0a-b3f3-459e65203bc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Uj2LFlahCUcj"
   },
   "outputs": [],
   "source": [
    "def house_prices_dataset(return_df=False, return_df_xy=False, price_max=400000, area_max=40000):\n",
    "  path = 'data/AmesHousing.csv'\n",
    "\n",
    "  df = pd.read_csv(path, na_values=('NaN', ''), keep_default_na=False)\n",
    "\n",
    "  rename_dict = {k:k.replace(' ', '').replace('/', '') for k in df.keys()}\n",
    "  df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "  useful_fields = ['LotArea',\n",
    "                  'Utilities', 'OverallQual', 'OverallCond',\n",
    "                  'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond',\n",
    "                  'HeatingQC', 'CentralAir', 'Electrical',\n",
    "                  '1stFlrSF', '2ndFlrSF','GrLivArea',\n",
    "                  'FullBath', 'HalfBath',\n",
    "                  'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
    "                  'Functional','PoolArea',\n",
    "                  'YrSold', 'MoSold'\n",
    "                  ]\n",
    "  target_field = 'SalePrice'\n",
    "\n",
    "  df.dropna(axis=0, subset=useful_fields+[target_field], inplace=True)\n",
    "\n",
    "  cleanup_nums = {'Street':      {'Grvl': 0, 'Pave': 1},\n",
    "                  'LotFrontage': {'NA':0},\n",
    "                  'Alley':       {'NA':0, 'Grvl': 1, 'Pave': 2},\n",
    "                  'LotShape':    {'IR3':0, 'IR2': 1, 'IR1': 2, 'Reg':3},\n",
    "                  'Utilities':   {'ELO':0, 'NoSeWa': 1, 'NoSewr': 2, 'AllPub': 3},\n",
    "                  'LandSlope':   {'Sev':0, 'Mod': 1, 'Gtl': 3},\n",
    "                  'ExterQual':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'ExterCond':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'BsmtQual':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtCond':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtExposure':{'NA':0, 'No':1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "                  'BsmtFinType1':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'BsmtFinType2':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'HeatingQC':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'CentralAir':  {'N':0, 'Y': 1},\n",
    "                  'Electrical':  {'':0, 'NA':0, 'Mix':1, 'FuseP':2, 'FuseF': 3, 'FuseA': 4, 'SBrkr': 5},\n",
    "                  'KitchenQual': {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Functional':  {'Sal':0, 'Sev':1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2':5, 'Min1':6, 'Typ':7},\n",
    "                  'FireplaceQu': {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'PoolQC':      {'NA':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Fence':       {'NA':0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv':4},\n",
    "                  }\n",
    "\n",
    "  df_X = df[useful_fields].copy()\n",
    "  df_X.replace(cleanup_nums, inplace=True)  # convert continous categorial variables to numerical\n",
    "  df_Y = df[target_field].copy()\n",
    "\n",
    "  x = df_X.to_numpy().astype(np.float32)\n",
    "  y = df_Y.to_numpy().astype(np.float32)\n",
    "\n",
    "  if price_max>0:\n",
    "    idxs = y<price_max\n",
    "    x = x[idxs]\n",
    "    y = y[idxs]\n",
    "\n",
    "  if area_max>0:\n",
    "    idxs = x[:,0]<area_max\n",
    "    x = x[idxs]\n",
    "    y = y[idxs]\n",
    "\n",
    "  return (x, y, df) if return_df else (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ddde272-6e2e-4696-98a1-da67b030e8aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-jcX7oYDFwzQ"
   },
   "outputs": [],
   "source": [
    "def house_prices_dataset_normed():\n",
    "    x, y = house_prices_dataset(return_df=False, price_max=-1, area_max=-1)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    features_scaled=scaler.fit_transform(x)\n",
    "\n",
    "    return features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abaf4d60-7a60-40ac-9e18-fb54c4bc47d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YqWU0eHts1RM"
   },
   "outputs": [],
   "source": [
    "x, y, df = house_prices_dataset(return_df=True)\n",
    "print(x.shape, y.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35651a6-f1f5-4105-b980-7778bbc6c450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "91nj7znzMEpA"
   },
   "outputs": [],
   "source": [
    "plt.plot(x[:, 0], y, '.')\n",
    "plt.xlabel('area, sq.ft')\n",
    "plt.ylabel('price, $');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a26ed431-10cb-433f-b7be-ae823361f041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "q7CNxkPdNB4L"
   },
   "source": [
    "## 3. Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598bf209-a92d-4b61-9c76-619b25c50b53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "j8wXhleONKgZ"
   },
   "outputs": [],
   "source": [
    "x, y = make_blobs(n_samples=1000, centers=[[0,0], [5,5], [10, 0]])\n",
    "colors = \"ygr\"\n",
    "for i, color in enumerate(colors):\n",
    "    idx = y == i\n",
    "    plt.scatter(x[idx, 0], x[idx, 1], c=color, edgecolor='gray', s=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd70e5a9-0355-4702-8033-7d5aec88d387",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8S1jwU4cXQX4"
   },
   "source": [
    "## 4. MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9f03e4a-d3db-422e-a7a8-a2ab26a5f117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "e2u82UQ5XQX4"
   },
   "source": [
    "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. The digits have been size-normalized and centered in a fixed-size image.\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting (taken from http://yann.lecun.com/exdb/mnist/). Each example is a 28x28 grayscale image and the dataset can be readily downloaded from Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4291baf0-8d30-43cc-a952-84be2781fecf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JaNaGGOkXQX5"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c40e09-918c-4427-a3bf-de1a3f6a7936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dlUY5gl8XQX7"
   },
   "source": [
    "Let's check few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab1c3ba6-d2a8-4d35-b5f2-11c5f3afc7c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qtYtGEDdXQX8"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, ax = plt.subplots(n, n, figsize=(2*n, 2*n))\n",
    "ax = [ax_xy for ax_y in ax for ax_xy in ax_y]\n",
    "for axi, im_idx in zip(ax, np.random.choice(len(train_images), n**2)):\n",
    "  im = train_images[im_idx]\n",
    "  im_class = train_labels[im_idx]\n",
    "  axi.imshow(im, cmap='gray')\n",
    "  axi.text(1, 4, f'{im_class}', color='r', size=16)\n",
    "  axi.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0249ddc4-e31b-4474-a3fa-cff44fcb1870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5MXcNBOBCUcy"
   },
   "source": [
    "## 5. Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5a20c66-d2dc-4342-8a0b-f78f7358a6f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "rANzstLwCUcy"
   },
   "source": [
    "`Fashion-MNIST` is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. (from https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be29002f-b078-4550-a176-c13a678ea9d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Woc5ld-HCUcz"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67a83c61-32e8-4900-8ea9-3334573f730d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FH2G-FAHCUc1"
   },
   "source": [
    "Let's check few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ed2fd1-d712-4967-83d3-28f04ce2abf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "90EhR8nmCUc1"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, ax = plt.subplots(n, n, figsize=(2*n, 2*n))\n",
    "ax = [ax_xy for ax_y in ax for ax_xy in ax_y]\n",
    "for axi, im_idx in zip(ax, np.random.choice(len(train_images), n**2)):\n",
    "  im = train_images[im_idx]\n",
    "  im_class = train_labels[im_idx]\n",
    "  axi.imshow(im, cmap='gray')\n",
    "  axi.text(1, 4, f'{im_class}', color='r', size=16)\n",
    "  axi.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a59a4ec-8307-4d39-a631-2d037a74d50f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xeaJnq9hCUc3"
   },
   "source": [
    "Each of the training and test examples is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b814072-e2e4-4bec-9d78-8de8b8c97752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "s_wxOrdWko8W"
   },
   "source": [
    "In this course we will use several synthetic and real-world datasets to illustrate the behavior of the models and exercise our skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf3f9d72-71cd-452b-ab4e-050610ef9bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Data visualization and low-dimensional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1faabe12-0804-4137-b55e-afd8741aa507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "diTExyW-L6Y0"
   },
   "source": [
    "**Unsupervised learning techniques** differ from supervised ones from the fact that data are not labelled (no supervision).\n",
    "\n",
    "We do not aim at fitting a mapping from $X$ to $Y$, but to understand patterns in the data cloud $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e6a71a3-1bed-4049-bc41-f5d9ec4b62af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Many datasets have a large number of features $D$ (design matrix of shape $N \\times D$). Dimensionality reduction aims at reducing the number of features $M$ (new design matrix of shape $N \\times M$), with $M \\ll D$, without losing information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaf773d6-6062-467c-a94d-0d0be28307f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Applications:\n",
    "\n",
    "- **EDA**: When $M=2$ or $M=3$ the dataset can also be visualized in a 2D or 3D plot, usable to perform exploratory data analysis, build visualization Apps and supporting feature engineering for complex data structures.\n",
    "\n",
    "- **DATA UNDERSTANDING**: Umap visualization may highlight dataset structures and outliers/data with poor quality or measurement errors. \n",
    "\n",
    "- **NOISE REDUCTION AND DATA COMPRESSION**: by performing dimensionality reduction the noise may be removed. This may simplify downstreams tasks (e.g. clustering) or fitting downstream models, using the reduced features instead of the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9b64861-3aec-4b92-9f42-536b3bfdf4b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Methods:\n",
    "\n",
    "Embedding techniques start from a local description of the environment of each sample point in the original space:\n",
    "\n",
    "- `t-Sne` uses a `statistical description` of the environment of a sample point ;\n",
    "- `UMAP` describes the `topology` of the environment through a generalized \"triangulation\" (simplex decomposition) ;\n",
    "\n",
    "The projection on the low-dimensional space is optimized in order to match as much as possible the description of the local environment.\n",
    "\n",
    "It is not the goal of this introduction to discuss the derivation of such approaches, which can be found in the references:\n",
    "\n",
    "https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1802.03426.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec1d7327-23dc-4b7f-9ae1-139620e0346b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Utilization in Python and examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eee896e5-5f83-44a1-8bee-6ead66822151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To begin with, we create a t-SNE object that we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd7fe322-0a9b-4da9-bbbc-23b094760673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tsne_model = TSNE(perplexity=30, n_components=2, learning_rate=200, early_exaggeration=4.0,init='pca',\n",
    "                      n_iter=2000, random_state=2233212, metric='euclidean', verbose=100 )\n",
    "\n",
    "umap_model = umap.UMAP(n_neighbors=30, n_components=2, random_state=1711)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f433acbc-3923-4e55-ba28-2fd9a3615a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 1: the Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe151ea1-9ee7-48f2-9d33-4798e20d4582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data= load_ex2_data_pca(seed=13423, n_add=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e0e6c05-0bef-4302-856f-348cef422101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20971774-be85-4953-b00d-50b3614b38d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(data[:,0], data[:,1],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd433be6-696e-451e-a838-891c40eea568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from utils.routines import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= load_ex2_data_pca(seed=1235, n_add=20)\n",
    "\n",
    "tsne_model = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3, verbose=1)\n",
    "\n",
    "tsne_heart = tsne_model.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8678c5a0-bfd7-4c18-b0e0-d5165db3788d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(tsne_heart[:,0],tsne_heart[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd5b8611-ce4e-4979-92c5-a1429e0013a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data= load_ex2_data_pca(seed=1235, n_add=20)\n",
    "\n",
    "tsne_model = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10, verbose=1)\n",
    "\n",
    "tsne_heart = tsne_model.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14644dd4-cc9a-43e8-8092-6086600b6bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(tsne_heart[:,0],tsne_heart[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea621de8-a390-43e3-889d-1e7d4f8e997c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=30, n_components=2, random_state=1711)\n",
    "\n",
    "umap_hart = umap_model.fit_transform(data)\n",
    "plt.scatter(umap_hart[:, 0], umap_hart[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ebdeb9f-dce5-4ba9-b8e3-9240557b393f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 2: Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5592bedd-6cc6-4015-bfda-c96240a21ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "n_examples = 5000\n",
    "data=train_images[:n_examples,:].reshape(n_examples,-1)\n",
    "data=data/255\n",
    "\n",
    "labels=train_labels[:n_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1cc7ed-6ab2-4a01-a2dc-4d077ffaf118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# not to run on COLAB\n",
    "\n",
    "# tsne_model = TSNE(perplexity=10, n_components=2, learning_rate=200,\n",
    "#                   early_exaggeration=4.0,init='pca',\n",
    "#                   n_iter=2000, random_state=2233212,\n",
    "#                   metric='euclidean', verbose=100, n_jobs=1)\n",
    "\n",
    "# tsne_mnist = tsne_model.fit_transform(data)\n",
    "\n",
    "# plt.scatter(tsne_mnist[:,0],tsne_mnist[:,1],c=labels,s=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "740a2ef9-1c20-4310-ba6d-ff1bdf39c661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=10, n_components=2, random_state=1711)\n",
    "umap_mnist = umap_model.fit_transform(data)\n",
    "plt.scatter(umap_mnist[:, 0], umap_mnist[:, 1], c=labels, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3dcaf1e-b1b1-435e-bb72-7f3e28d46b03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 3: Fashion_Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca21687d-d51c-4c67-bbeb-53cd21f79abd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "n_examples = 5000\n",
    "data=train_images[:n_examples,:].reshape(n_examples,-1)\n",
    "data=data/255\n",
    "\n",
    "labels=train_labels[:n_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684d807a-42c9-4a2c-a73d-2099d4d4843d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# not to run on COLAB\n",
    "\n",
    "# tsne_model = TSNE(perplexity=50, n_components=2, learning_rate=200, early_exaggeration=4.0,init='pca',\n",
    "#                      n_iter=1000, random_state=2233212, metric='euclidean', verbose=100 )\n",
    "\n",
    "# tsne_fmnist = tsne_model.fit_transform(data)\n",
    "\n",
    "# plt.scatter(tsne_fmnist[:,0],tsne_fmnist[:,1],c=labels,s=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec7a4455-842e-4d10-87c7-0faab9a62543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=50, n_components=2, random_state=1711)\n",
    "umap_fmnist = umap_model.fit_transform(data)\n",
    "plt.scatter(umap_fmnist[:, 0], umap_fmnist[:, 1], c=labels, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5cc1ab8-d6fe-4322-9962-bd82ea52d53e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 4: AMES dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15f51ba9-9a53-4fd1-91fb-981d4ff323ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the case of the AMES dataset we must normalize somehow the dataset. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfdb6bb9-d0e4-49a8-adb1-dbfc10335232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = house_prices_dataset_normed()\n",
    "x, y, df = house_prices_dataset(return_df=True, price_max=-1, area_max=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36428afa-751c-42e6-a8db-751be758a946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=30, n_components=2, random_state=1711)\n",
    "umap_houses = umap_model.fit_transform(data)\n",
    "plt.scatter(umap_houses[:, 0], umap_houses[:, 1], s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9d720d5-db7b-4150-a168-885a32b81234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In such a situation we do not have 'labels' to superimpose. To understand what are the features characterizing each clusters it time consuming and there is no general-purpose method.\n",
    "\n",
    "The following techniques can be used:\n",
    "\n",
    "1. **Visualization of Individual points:** Make an interactive App (e.g. using dash) that permits to visualize points quickly (e.g. if the dataset is made of images or texts)\n",
    "\n",
    "2. **Colour plots:** Color the points according to a selected variable and check if points get mixed.\n",
    "\n",
    "Using clustering techniques (you will here more about them next session), one can attach a cluster label to each point. After this step, an other range of exploration methodologies can be performed:\n",
    "\n",
    "3. **Visualization of Centroids:** Make the mean of the each features across all members of one cluster. Compare between clusters. \n",
    "\n",
    "4. **Analyze distributions:** Make a descriptive analysis of the populations in the different clusters.\n",
    "\n",
    "5. **Use cluster indexes as labels and apply supervised machine learning methods.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f082513-7f31-486a-91d4-aa4801015c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As an example we start an analysis using approach 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1b8a6ab-ecc3-4d92-8517-8d16a089f9d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=30, gen_min_span_tree=True)\n",
    "clusterer.fit(umap_houses)\n",
    "\n",
    "scatter = plt.scatter(umap_houses[:, 0], umap_houses[:, 1], c=clusterer.labels_, cmap='viridis', s=2)\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "labels=clusterer.labels_\n",
    "classes=set(labels)-set([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8cfffd-8d7a-4333-8853-d892a06ab67e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "useful_fields = ['LotArea',\n",
    "                'Utilities', 'OverallQual', 'OverallCond',\n",
    "                'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond',\n",
    "                'HeatingQC', 'CentralAir', 'Electrical',\n",
    "                '1stFlrSF', '2ndFlrSF','GrLivArea',\n",
    "                'FullBath', 'HalfBath',\n",
    "                'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
    "                'Functional','PoolArea',\n",
    "                'YrSold', 'MoSold'\n",
    "                ]\n",
    "df = pd.DataFrame(data, columns=useful_fields)\n",
    "df['cluster']=clusterer.labels_\n",
    "\n",
    "# Select only the points that have been assigned to a cluster (NB: hdbscan may fail to assign a point to a cluster)\n",
    "df_2=df[df['cluster']!=-1]\n",
    "df_2=df_2.sort_values(by='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6f760f-aaa0-4eb1-b673-0abc4082bb38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_clusters=len(set(df_2['cluster']))\n",
    "print(n_clusters)\n",
    "for i in range(n_clusters):\n",
    "    pop=df_2[df_2['cluster']==i].shape[0]\n",
    "    print(f'Cluster {i} has population: {pop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8120f846-e6cc-43bf-a784-e906a63b8f4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "for cluster in range(n_clusters):\n",
    "        X = df_2.drop('cluster', axis=1)  \n",
    "        y = df_2['cluster']            \n",
    "        # binarization\n",
    "        y = [1 if i==cluster else 0 for i in y]\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        rf_model = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=5)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        # Print evaluation metrics\n",
    "        print(f\"Accuracy: {accuracy}\") ## --> Note that this is an inbalanced dataset\n",
    "        print(conf_matrix)\n",
    "        plt.figure()\n",
    "        plt.barh(useful_fields,\n",
    "                rf_model.feature_importances_)\n",
    "        plt.title(f'cluster: {cluster} - {conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20f22f68-368e-42af-96d1-2e0c9fb99be7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "NB: a similar result approach can be pursued following the SHAP method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1efacce-260f-4f8e-a05e-3fe6e81a4f83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "afROKfT591kS"
   },
   "source": [
    "## 2. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa1c2899-03bf-4df0-947b-1739026e8a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PCA can be considered as a dimensionality reduction technique where there is a constrain of the reducting to be a linear projection. As a consequence:\n",
    "\n",
    "1- only few datasets can be projected to $M=2$ dimensions.\n",
    "\n",
    "2- the amount of information that can be extracted is higher and is easier to interpret when the variables have all the same units and numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f2ecd55-7a5d-496b-b26a-ea03c91f10e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Y0iypmtDL6Y1"
   },
   "source": [
    "Let's start with the example that we will use to make the theory more concrete. We will take a dataset from from kaggle https://www.kaggle.com/datasets/miroslavsabo/young-people-survey?resource=download (already downloaded for you in the folder `data`)\n",
    "\n",
    "The datasets consists of the results of a survey about the music preferences of several students, arriving at the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T14:09:42.322377Z",
     "start_time": "2022-09-27T14:09:42.283713Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55ff5af4-5a8b-40eb-80c3-ee5f707186dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "J7ep6OIJL6Y1"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/Tao-Pi/CAS-Applied-Data-Science/refs/heads/main/DSF5%20-%20copy/data/responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "053bf9ad-7dae-4fa8-8e11-00093408d0ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "vuOinT9cL6Y4",
    "outputId": "364e82a5-b5e0-45dc-fc67-0e66c36285a0"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80169fbd-e626-463f-8313-c200fec2d223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKZDi4ngL6Y4",
    "outputId": "87bcddad-0d73-4ab6-a873-f2eee03e8484"
   },
   "outputs": [],
   "source": [
    "music_columns=data.columns[:19]\n",
    "print(music_columns)\n",
    "music_data=data[music_columns].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4590668d-39d8-4f75-a490-9432d11d2495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pqkUey6GL6Y4"
   },
   "source": [
    "The answers are of course correlated and we expect to have typical patterns recurring, that we define as people liking similar types of songs.\n",
    "\n",
    "The patterns may be also mixing, for e.g. a class of people may like classic `Pop` and `Reggae`, but not `Latino`. An other class may like `Latino` and `Reggae`, but not `Pop`.\n",
    "\n",
    "PCA will help to find these typical patterns and their number in a data driven fashion. As we will see these patterns will naturally appear when trying to compress data in a lower dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b226d32d-ca1a-4899-8ffe-f79473ad7111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cXqNWQWT91kU"
   },
   "source": [
    "## 2.1 Theory overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce9b75bc-888c-4a6a-b06a-6ec4b4f2fc31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YydjP9pLL6Y4"
   },
   "source": [
    "We will look at PCA from the point of view of `dimensionaliy reduction`.\n",
    "\n",
    "**Objective:** PCA is used for dimensionality reduction when we have a large number $D$ of features with non-trivial intercorrelation ( data redundancy ) and to isolate relevant features. The number of features $D$ defines the original dimension of the dataset. Each sample defines a vector of dimensionality $D$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d61c6ab0-efa2-45dc-99d1-fe130da78b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Q6iH35oOL6Y4"
   },
   "source": [
    "    QUESTION: what are the starting vectors in our survey dataset? How many do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:13:53.622053Z",
     "start_time": "2022-09-27T12:13:53.611428Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60939702-ff4b-4073-8767-7202de6a5d02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x74cyGHiL6Y4"
   },
   "source": [
    "PCA provides a new set of $M$ uncorrelated features for every data point, with $M \\le D$. The new features are:\n",
    "\n",
    "- a linear combination of the original ones ;\n",
    "- uncorrelated between each other ;\n",
    "\n",
    "If $M \\ll D$ we get an effective dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:17:23.351734Z",
     "start_time": "2022-09-27T12:17:23.345972Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20e2c253-d429-4f5b-a95f-bac7f98c62dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DWaB15hBL6Y4"
   },
   "source": [
    "    QUESTION: Does the number of data points changes after applying PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60029807-ca6d-4ed3-9877-97fcd75c1891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **PCA as a Linear Dimensionality Reduction**\n",
    "\n",
    "Each data point, indexed by $p=1..N$, starts from an original $D$-dimensional space:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^p = (x^p_{1},\\ldots,x^p_{D})\n",
    "$$\n",
    "\n",
    "where $D$ is the **number of features**.\n",
    "\n",
    "We want to find a more economical representation with $M$ components, e.g. $M=2$ (two coordinates):\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^p = (s^p_{1},\\ldots,s^p_{M})\n",
    "$$\n",
    "\n",
    "How are the new components related to the previous ones? We have a reconstruction property:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^p \\approx \\mathbf{x}^p_M \\equiv \\mathbf{m} + \\sum_{j=1}^M s^p_{j} \\ \\mathbf{v_{j}}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{m}$ represents the mean of each feature for the entire dataset. Note that:\n",
    "\n",
    "- PCA optimizes $\\mathbf{v_{j}},\\ j=1..M$, called the **principal components** or **principal vectors**, so that the reconstruction property holds optimally for every fixed $M$, minimizing the loss of information.\n",
    "\n",
    "---\n",
    "\n",
    "### **More on the Principal Vectors: Explained Variance**\n",
    "\n",
    "**Orthonormality:**\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 = (v_{1,1},\\ldots,v_{1,D}), ..., \\mathbf{v}_M = (v_{M,1},\\ldots,v_{M,D})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{i} \\cdot \\mathbf{v}_{j} = \\delta_{i,j}\n",
    "$$\n",
    "\n",
    "The variance of the points in the dataset can be approximated by the variance of the reconstructed points. In particular, we have the decomposition of the total variance:\n",
    "\n",
    "$$\n",
    "S^2 = \\frac{1}{N}\\sum_{p=1}^{N}  |\\mathbf{x}_p - \\mathbf{m}|^2 = \\epsilon_1 + \\epsilon_2 + \\ldots + \\epsilon_D\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\epsilon_1$: variance of the reconstructed points $\\mathbf{x}^p_{M=1}$, also called the variance explained by the first principal component\n",
    "- $\\epsilon_1 + \\epsilon_2$: variance of the reconstructed points $\\mathbf{x}^p_{M=1}$, also called the variance explained by the first two components\n",
    "- $\\ldots$\n",
    "- $S^2 = \\epsilon_1 + \\epsilon_2 + \\ldots + \\epsilon_D$\n",
    "\n",
    "It turns out that **minimizing the reconstruction error is equivalent to maximizing the variance**. The $\\epsilon$ values are called the **explained variance**.\n",
    "\n",
    "The ratios:\n",
    "\n",
    "$$\n",
    "\\rho_1 = \\frac{\\epsilon_1}{S^2},\\ \\rho_2 = \\frac{\\epsilon_2}{S^2},\\ldots\n",
    "$$\n",
    "\n",
    "are called the **explained variance ratio**, and their cumulative sums:\n",
    "\n",
    "$$\n",
    "r_1 = \\frac{\\epsilon_1}{S^2},\\ r_2 = \\frac{\\epsilon_1 + \\epsilon_2}{S^2},\\ldots,\\ r_D = 1\n",
    "$$\n",
    "\n",
    "are the **cumulative explained variance ratio**.\n",
    "\n",
    "The plot of the explained variance ratio as a function of the number of components is called a *scree plot* and serves to select an optimal value of $M$ (if it exists). If $M$ is small, we have obtained a new, more compact data representation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Terminology to Remember**\n",
    "\n",
    "- **Principal components:** A sequence of orthonormal vectors $\\mathbf{v}_1,\\ldots,\\mathbf{v}_n$. These vectors represent the typical patterns found in the data, ordered from most to least important.\n",
    "- **Scores:** For every sample point $p$, the new features (scores) are called $s_{p,i}$. They can be computed from the original representation and the principal vectors with a scalar product: $\\mathbf{x}_p \\cdot \\mathbf{v}_i$\n",
    "- **Explained variance:** For every $M$, the ratio between the variance of the reconstructed vectors and the total variance. The number of components is chosen by selecting an optimal $M$. The plot of the explained variance as a function of $M$ is called a *scree plot*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce9d39fe-88a9-42b0-b5eb-efd0d9c4fd6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hF-FTX_P91ka"
   },
   "source": [
    "### 2.2 PCA - Example 1: music dataset\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T14:44:10.677074Z",
     "start_time": "2022-09-27T14:44:10.652371Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79c458d-5bcb-4d3f-b98f-ccf2551efa41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FeaMbSd9L6Y5",
    "outputId": "17ac3312-5ad1-406a-a80b-bb638658130a"
   },
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "pca.fit(music_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a7b0b77-9cc1-46c2-b4ad-e11449d94af4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "scW5XkGvL6Y5"
   },
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44179c7b-6d18-476c-b257-665f3c803e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ASRvM6OKL6Y6"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pca.components_.transpose(),\n",
    "                  columns = [f'V_{i+1}' for i in range(len(music_columns))],\n",
    "                  index=music_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1c0b1f4-28b4-462c-8b3b-8b8f1d81cb78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7qiQtvp4L6Y6"
   },
   "outputs": [],
   "source": [
    "for vector in ['V_1','V_2','V_3','V_4']:\n",
    "    plt.figure()\n",
    "    plt.title(vector)\n",
    "    plt.plot(np.arange(len(music_columns)),list(df[vector]),'-o')\n",
    "    _=plt.xticks(np.arange(len(music_columns)),music_columns, rotation=90)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08044123-2b00-4d96-aba3-017ef46a1526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 PCA - Example 2: Using the scores for visualization\n",
    "\n",
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/pca-ames.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c0da671-74a7-459f-83ba-9027fbcef8e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/pca-wine.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e16d047d-f78f-458f-93a4-f97200d3380f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/pca-breast-cancer.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a2fee0a-e311-43f9-ada1-fd501d7eef4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Note 2: Intepretation of PCA plot when M=2\n",
    "\n",
    "When $M=2$ the scatterplot of $s_1$ vs. $s_2$ is an effective 2 dimensional visualization of the dataset. If such a scatterplot shows actual patterns in the data depends on the dataset. \n",
    "\n",
    " See https://www.fbbva.es/wp-content/uploads/2017/05/dat/DE_2010_biplots_in_practice.pdf for a deeper introduction on visualization using PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3f8d76b-be02-4bc9-9dc2-6bc95235f7ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3 PCA Example 3 - Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6573c52f-59fa-4a6f-88a8-d9f717b3d30f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import random_noise\n",
    "\n",
    "# Example adapted from https://scikit-learn.org/stable/auto_examples/applications/plot_digits_denoising.html: \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_digits(X, title):\n",
    "    \"\"\"Small helper function to plot 100 digits.\"\"\"\n",
    "    fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(8, 8))\n",
    "    for img, ax in zip(X, axs.ravel()):\n",
    "        ax.imshow(img.reshape((16, 16)), cmap=\"Greys\")\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=24)\n",
    "X, y = fetch_openml(data_id=41082, as_frame=False, return_X_y=True)\n",
    "X_noise = random_noise(X, mode='gaussian', var=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c02b99a-84f6-49c3-9876-ac873321a541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_digits(X, \"Uncorrupted test images\")\n",
    "plot_digits(X_noise, f\"Noisy test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3d07202-644b-40a2-b53d-a984872335bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=32)\n",
    "pca.fit(X)\n",
    "X_reconstructed = pca.inverse_transform(pca.transform(X))\n",
    "plot_digits(X_reconstructed,'reconstructed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db3dd671-47e2-48a1-8669-71de9238c530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "w3AtpLmQef_R"
   },
   "source": [
    "## Final Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b73e4bb7-0fc4-4ee1-92f0-de8de21f1635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Note 1: Uncorrelation of PCA scores:\n",
    "\n",
    "\n",
    "PCA is able therefore to make this mapping:\n",
    "\n",
    "$(x_1,...,x_D) \\rightarrow (y_1,..,y_M)$\n",
    "\n",
    "Here we focused on data compression, but it is also very important that $y_1,...,y_M$ are uncorrolated. Being uncorrelated means (roughly) that in our dataset we can change one variable without affecting the others. The dimensions 1,...,M are often therefore more interpretable and providing more information.\n",
    "\n",
    "Always remember that the results of UMAP AND PCA depend on normalization of variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f2e16b8-2116-4bcb-93d1-761b91bf5375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Course_2",
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [
    "8UQgU5I-lEll",
    "-2uMw5C4CUcj",
    "q7CNxkPdNB4L",
    "8S1jwU4cXQX4",
    "5MXcNBOBCUcy"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_dsf5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
