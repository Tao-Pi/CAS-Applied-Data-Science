{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7771b766-8c8d-4ced-9498-9df39448acbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZMi612g2a1wO"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neworldemancer/DSF5/blob/master/Course_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d241c888-d654-447f-9693-0b09748525ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Nd5wH914a1wU"
   },
   "source": [
    "# Introduction to machine learning & Data Analysis\n",
    "\n",
    "Basic introduction on how to perform typical machine learning tasks with Python.\n",
    "\n",
    "Prepared by Mykhailo Vladymyrov & Aris Marcolongo,\n",
    "Data Science Lab, University Of Bern, 2023\n",
    "\n",
    "This work is licensed under <a href=\"https://creativecommons.org/share-your-work/public-domain/cc0/\">CC0</a>.\n",
    "\n",
    "# Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7950873-22ca-4b7c-9f80-a9d627713d41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LzEnLAMt3De2"
   },
   "source": [
    "# 0. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc807d3f-4f12-4939-ae23-719081dec851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run code below, just once \n",
    "# %pip install --upgrade \"numpy<2.0.0\"\n",
    "# %pip install imageio tensorflow\n",
    "# dbutils.library.restartPython()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e663a61a-3838-4f52-8ff0-8492aaa4b0c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hVJn0ilgOS8F"
   },
   "outputs": [],
   "source": [
    "from matplotlib import  pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "from time import time as timer\n",
    "\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from matplotlib import animation\n",
    "from matplotlib import cm\n",
    "from IPython.display import HTML\n",
    "from sklearn.datasets import make_blobs\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"  # for matplotlib 2.1 and above, uses JavaScript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f00b03f1-a0d1-423a-913c-68c4d5365d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7ZPG2uLJbSju"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tarfile\n",
    "import os\n",
    "from packaging import version\n",
    "import shutil\n",
    "import sys \n",
    "\n",
    "def download_and_extract_data(\n",
    "    url=\"https://github.com/neworldemancer/DSF5/raw/master/colab_material.tgz\",\n",
    "    target_dir=\"data\",\n",
    "    fname=\"colab_material.tgz\",\n",
    "    update_folder=False\n",
    "):\n",
    "    \"\"\"Download and extract a tar.gz dataset into target_dir.\"\"\"\n",
    "    \n",
    "    if update_folder and os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        cache_dir = os.path.abspath(\".\")\n",
    "\n",
    "        if version.parse(tf.__version__) >= version.parse(\"2.13.0\"):\n",
    "            # new behavior: fname must be only a filename\n",
    "            path = tf.keras.utils.get_file(\n",
    "                fname=fname,\n",
    "                origin=url,\n",
    "                cache_dir=cache_dir\n",
    "            )\n",
    "        else:\n",
    "            # old behavior: can pass full path\n",
    "            path = tf.keras.utils.get_file(\n",
    "                fname=os.path.join(cache_dir, fname),\n",
    "                origin=url\n",
    "            )\n",
    "        # extract tar into target_dir\n",
    "        with tarfile.open(path, \"r:gz\") as tar:\n",
    "            tar.extractall(target_dir)\n",
    "    else:\n",
    "        print('Data already present. Use update_folder = True to overwrite/update if desired.')\n",
    "    return os.path.abspath(target_dir)\n",
    "\n",
    "data_path = download_and_extract_data(update_folder=False)\n",
    "sys.path.append(data_path)\n",
    "print(\"Data available at:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6270c164-f415-4386-9d0f-d1500b103fa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tWsA0mkObhN-"
   },
   "outputs": [],
   "source": [
    "from utils.routines import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1ee7c3f-01ad-4820-b0f3-b39b13c39994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pclZR6uFklf_"
   },
   "source": [
    "# 1. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "455b4731-049b-40e2-a61e-351be2ed21d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "s_wxOrdWko8W"
   },
   "source": [
    "In this course we will use several synthetic and real-world datasets to illustrate the behavior of the models and exercise our skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c47741e-0ad8-414a-a1d2-5c0e7cd443f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8UQgU5I-lEll"
   },
   "source": [
    "## 1. Synthetic linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16e55a4d-2f88-447c-9108-6636431860e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jGfWOWRjlWPa"
   },
   "outputs": [],
   "source": [
    "def get_linear(n_d=1, n_points=10, w=None, b=None, sigma=5):\n",
    "  x = np.random.uniform(0, 10, size=(n_points, n_d))\n",
    "\n",
    "  w = w or np.random.uniform(0.1, 10, n_d)\n",
    "  b = b or np.random.uniform(-10, 10)\n",
    "  y = np.dot(x, w) + b + np.random.normal(0, sigma, size=n_points)\n",
    "\n",
    "  print('true slopes: w =', w, ';  b =', b)\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "898a1332-9fe6-4a48-bf37-f8ca336ac111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5RLYxGy_nBZG"
   },
   "outputs": [],
   "source": [
    "x, y = get_linear(n_d=1, sigma=1)\n",
    "plt.plot(x[:, 0], y, '*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8410cb-68e5-4eb2-897b-c60166caa4f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "10ODDOp4nX4S"
   },
   "outputs": [],
   "source": [
    "n_d = 2\n",
    "x, y = get_linear(n_d=n_d, n_points=100)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], y, marker='x', color='b',s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "471254de-5751-49b1-b22f-74f5995cf726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FJ5rjq7fIe8Q"
   },
   "source": [
    "## 2. House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f317e83-56a1-4ef0-a5aa-2074a0970365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "A-45usskInlD"
   },
   "source": [
    "Subset of the Ames Houses dataset: http://jse.amstat.org/v19n3/decock.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282425d1-98f3-418b-bb6c-5331b5a11f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def house_prices_dataset(return_df=False, return_df_xy=False, price_max=400000, area_max=40000):\n",
    "  path = 'data/AmesHousing.csv'\n",
    "\n",
    "  df = pd.read_csv(path, na_values=('NaN', ''), keep_default_na=False,  )\n",
    "\n",
    "  rename_dict = {k:k.replace(' ', '').replace('/', '') for k in df.keys()}\n",
    "  df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "  useful_fields = ['LotArea',\n",
    "                  'Utilities', 'OverallQual', 'OverallCond',\n",
    "                  'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond',\n",
    "                  'HeatingQC', 'CentralAir', 'Electrical',\n",
    "                  '1stFlrSF', '2ndFlrSF','GrLivArea',\n",
    "                  'FullBath', 'HalfBath',\n",
    "                  'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
    "                  'Functional','PoolArea',\n",
    "                  'YrSold', 'MoSold'\n",
    "                  ]\n",
    "  target_field = 'SalePrice'\n",
    "\n",
    "  df.dropna(axis=0, subset=useful_fields+[target_field], inplace=True)\n",
    "\n",
    "  cleanup_nums = {'Street':      {'Grvl': 0, 'Pave': 1},\n",
    "                  'LotFrontage': {'NA':0},\n",
    "                  'Alley':       {'NA':0, 'Grvl': 1, 'Pave': 2},\n",
    "                  'LotShape':    {'IR3':0, 'IR2': 1, 'IR1': 2, 'Reg':3},\n",
    "                  'Utilities':   {'ELO':0, 'NoSeWa': 1, 'NoSewr': 2, 'AllPub': 3},\n",
    "                  'LandSlope':   {'Sev':0, 'Mod': 1, 'Gtl': 3},\n",
    "                  'ExterQual':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'ExterCond':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'BsmtQual':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtCond':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtExposure':{'NA':0, 'No':1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "                  'BsmtFinType1':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'BsmtFinType2':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'HeatingQC':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'CentralAir':  {'N':0, 'Y': 1},\n",
    "                  'Electrical':  {'':0, 'NA':0, 'Mix':1, 'FuseP':2, 'FuseF': 3, 'FuseA': 4, 'SBrkr': 5},\n",
    "                  'KitchenQual': {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Functional':  {'Sal':0, 'Sev':1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2':5, 'Min1':6, 'Typ':7},\n",
    "                  'FireplaceQu': {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'PoolQC':      {'NA':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Fence':       {'NA':0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv':4},\n",
    "                  }\n",
    "\n",
    "  df_X = df[useful_fields].copy()\n",
    "  df_X.replace(cleanup_nums, inplace=True)  # convert continous categorial variables to numerical\n",
    "  df_Y = df[target_field].copy()\n",
    "\n",
    "  x = df_X.to_numpy().astype(np.float32)\n",
    "  y = df_Y.to_numpy().astype(np.float32)\n",
    "\n",
    "  if price_max>0:\n",
    "    idxs = y\n",
    "    idxs = x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "289f55e2-9c6b-4909-9db9-835d0a1e2671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dVv2ID96IyN0"
   },
   "outputs": [],
   "source": [
    "def house_prices_dataset_normed(data_path='/content/data'):\n",
    "    x, y = house_prices_dataset(return_df=False, price_max=-1, area_max=-1, data_path=data_path)\n",
    "    scaler=StandardScaler()\n",
    "    features_scaled=scaler.fit_transform(x)\n",
    "    return features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0beec59b-7f26-4619-8d66-2a6e673fb17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YqWU0eHts1RM"
   },
   "outputs": [],
   "source": [
    "x, y, df = house_prices_dataset(return_df=True)\n",
    "print(x.shape, y.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3790a6d-cd03-4313-a6f2-9831fa7f55df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21bedd0a-7a46-4c60-a3bc-59a42f162291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YDtzVS-1Mxxe"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567caec7-3224-427f-bca4-3cac286470f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "91nj7znzMEpA"
   },
   "outputs": [],
   "source": [
    "plt.plot(x[:, 0], y, '.')\n",
    "plt.xlabel('area, sq.ft')\n",
    "plt.ylabel('price, $');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0afc363-9c6e-49fb-82f3-9683c1634563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "q7CNxkPdNB4L"
   },
   "source": [
    "## 3. Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b579ce-6490-40ce-b60d-f95a71ae7567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "j8wXhleONKgZ"
   },
   "outputs": [],
   "source": [
    "x, y = make_blobs(n_samples=1000, centers=[[0,0], [5,5], [10, 0]])\n",
    "colors = \"ygr\"\n",
    "for i, color in enumerate(colors):\n",
    "    idx = y == i\n",
    "    plt.scatter(x[idx, 0], x[idx, 1], c=color, edgecolor='gray', s=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316b2293-149f-460e-ba82-8fdb643c0b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NKcmdcZf0VO8"
   },
   "outputs": [],
   "source": [
    "x, y = make_blobs(n_samples=1000, centers=[[0,0], [5,5], [10, 0]])\n",
    "\n",
    "transformation = [[0.4, 0.2], [-0.4, 1.2]]  # affine transformation matrix\n",
    "x = np.dot(x, transformation)               # applied to point coordinated to make blobs less separable\n",
    "\n",
    "colors = \"ygr\"\n",
    "for i, color in enumerate(colors):\n",
    "    idx = y == i\n",
    "    plt.scatter(x[idx, 0], x[idx, 1], c=color, edgecolor='gray', s=25)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3162040-bec4-483c-a1e6-817cc705da7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8S1jwU4cXQX4"
   },
   "source": [
    "## 4. MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "352ba0d1-d868-4d26-a355-2dbfbd870b72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "e2u82UQ5XQX4"
   },
   "source": [
    "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. The digits have been size-normalized and centered in a fixed-size image.\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting (taken from http://yann.lecun.com/exdb/mnist/). Each example is a 28x28 grayscale image and the dataset can be readily downloaded from Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32e64c91-aa0b-43aa-ae56-c693a7e8f097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JaNaGGOkXQX5"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "639657b8-6ddb-4e7b-95d4-f1969f6d1f89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dlUY5gl8XQX7"
   },
   "source": [
    "Let's check few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f3c534e-9fc9-4a84-b705-54cfb0d75d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qtYtGEDdXQX8"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, ax = plt.subplots(n, n, figsize=(2*n, 2*n))\n",
    "ax = [ax_xy for ax_y in ax for ax_xy in ax_y]\n",
    "for axi, im_idx in zip(ax, np.random.choice(len(train_images), n**2)):\n",
    "  im = train_images[im_idx]\n",
    "  im_class = train_labels[im_idx]\n",
    "  axi.imshow(im, cmap='gray')\n",
    "  axi.text(1, 4, f'{im_class}', color='r', size=16)\n",
    "  axi.grid(False)\n",
    "plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f223a11-e6c8-4912-808e-9e3352e161f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ITfbaOgfYNsq"
   },
   "source": [
    "## 5. Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58e59311-3e46-438b-a9b7-9a0a2c23d9de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jgzzOS7YYTru"
   },
   "source": [
    "`Fashion-MNIST` is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. (from https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c725e65f-8605-461d-b49e-447cc1a773a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RcV2gzmuYljJ"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ca0960-97a5-4dd4-9ea2-17fbbe7f62df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SPw6-GoPbT6U"
   },
   "source": [
    "Let's check few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90fbe2c-8bfc-4b0c-a3cf-e0d56b1b8779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tHFd0sFHY4Li"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, ax = plt.subplots(n, n, figsize=(2*n, 2*n))\n",
    "ax = [ax_xy for ax_y in ax for ax_xy in ax_y]\n",
    "for axi, im_idx in zip(ax, np.random.choice(len(train_images), n**2)):\n",
    "  im = train_images[im_idx]\n",
    "  im_class = train_labels[im_idx]\n",
    "  axi.imshow(im, cmap='gray')\n",
    "  axi.text(1, 4, f'{im_class}', color='r', size=16)\n",
    "  axi.grid(False)\n",
    "plt.tight_layout(0,0,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "449cb551-938a-4705-993b-d8a07cacb559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b2LkoWfZEi4g"
   },
   "outputs": [],
   "source": [
    "fmnist_class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee88afb-1fda-489d-980b-1f6f06117a50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iHEA0tCLagoV"
   },
   "source": [
    "Each of the training and test examples is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c77f199-d215-4ebb-b7e3-59b1225d4bac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x2NWxK0BFwyw"
   },
   "source": [
    "## 6. Weather dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5816f91b-b8e7-431e-9ffc-c03a2d5dc3d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LKsTkrMkGB7d"
   },
   "source": [
    "This is a weather time series [dataset](https://www.bgc-jena.mpg.de/wetter/) recorded by the Max Planck Institute for Biogeochemistry\n",
    "It contains weather reacord for 8 years of observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5909f14-96db-4349-99e9-492bd99e4184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "D_bXLpwxGTbZ"
   },
   "outputs": [],
   "source": [
    "def get_weather_df():\n",
    "  # inspired by https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "  # download and extract dataset\n",
    "  zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "  csv_path, _ = os.path.splitext(zip_path)\n",
    "\n",
    "  # load into pandas df\n",
    "  df = pd.read_csv(csv_path)\n",
    "\n",
    "  # dataset contains records every 10 min, we use hourly records only, thus\n",
    "  # slice [start:stop:step], starting from index 5 take every 6th record\n",
    "  df = df[5::6]\n",
    "\n",
    "  # replace errors in wind velocity to 0\n",
    "  wv = df['wv (m/s)']\n",
    "  bad_wv = wv == -9999.0\n",
    "  wv[bad_wv] = 0.0\n",
    "\n",
    "  max_wv = df['max. wv (m/s)']\n",
    "  bad_max_wv = max_wv == -9999.0\n",
    "  max_wv[bad_max_wv] = 0.0\n",
    "\n",
    "  # obtain timestamps from text time format\n",
    "  date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
    "  timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "  # genarate cyclic features for year and day\n",
    "  day = 24*60*60\n",
    "  year = (365.2425) * day\n",
    "\n",
    "  df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "  df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "  df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "  df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deecf60d-9b72-418b-a628-7ce20abd2439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DsYDOZZKI7_P"
   },
   "outputs": [],
   "source": [
    "weather_df = get_weather_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26944827-cc12-4c64-9992-722beee52ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "yQHfhrBMJA5w"
   },
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8034bbb-fa46-474d-b111-04b572b571aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wPUvJcY3JjJa"
   },
   "outputs": [],
   "source": [
    "weather_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb6b457e-976c-4226-b48a-9b056909791d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "T7qIhgZuMGW4"
   },
   "outputs": [],
   "source": [
    "plt.plot(weather_df['Year cos'])\n",
    "plt.plot(weather_df['Year sin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e896941a-6862-4ffc-b9d0-500b1ad21915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WxziDnFwLqL0"
   },
   "outputs": [],
   "source": [
    "plt.plot(weather_df['Day cos'][:7*24])\n",
    "plt.plot(weather_df['Day sin'][:7*24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b29c6adc-6fe3-4114-9a84-f583064d2864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tDQkIP4cJxuW"
   },
   "outputs": [],
   "source": [
    "def gen_future_T_dataset(X_len=24, Y_offset=48,\n",
    "                         X_features=['p (mbar)', 'T (degC)', 'rh (%)', 'wv (m/s)', 'wd (deg)', 'Day sin', 'Day cos', 'Year sin', 'Year cos'],\n",
    "                         Y_features='T (degC)',\n",
    "                         standardize=True,\n",
    "                         oversample=10\n",
    "                         ):\n",
    "  \"\"\"\n",
    "  Generates pairs of input-label, using sequence of `X_len` samples as input\n",
    "  and value at offset `Y_offset` from start of this sequence as label.\n",
    "  Sample sequnces arte taken at random positions throughout the dataset.\n",
    "  Number of samples is obtained assuming non-overlaping wondows.\n",
    "  Oversampling factor allows to increase this value.\n",
    "\n",
    "  Args:\n",
    "    X_len (int): length of sample sequence\n",
    "    Y_offset (int): offset to the target value from the sequence start\n",
    "    X_features (list or str): features to be used as input\n",
    "    Y_features (list or str): features to be used as labels\n",
    "    standardize (Bool): flag whether to standardize the columns\n",
    "    oversample (int): increases number of samples by this factor wrt baseline\n",
    "                      n = len(df) // (Y_offset+1)\n",
    "  \"\"\"\n",
    "  weather_df = get_weather_df()\n",
    "\n",
    "  if standardize:\n",
    "    mean = weather_df.mean()\n",
    "    std = weather_df.std()\n",
    "    weather_df = (weather_df - mean) / std\n",
    "\n",
    "  df_X = weather_df[X_features]\n",
    "  df_Y = weather_df[Y_features]\n",
    "\n",
    "  n_records = len(df_X)\n",
    "  sample_len = Y_offset+1\n",
    "  n_samples = int((n_records-sample_len)//sample_len*oversample)\n",
    "  offsets = np.random.randint(0, n_records-sample_len, size=n_samples)\n",
    "  offsets.sort()\n",
    "\n",
    "  X = []\n",
    "  Y = []\n",
    "  for o in offsets:\n",
    "    X.append(np.array(df_X[o:o+X_len]))\n",
    "    Y.append(np.array(df_Y[o+Y_offset:o+Y_offset+1]))\n",
    "\n",
    "  X = np.stack(X)\n",
    "  Y = np.concatenate(Y)\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc83e1a-75da-4762-8303-ec6a8f47e544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "m-uVf1AOPLIT"
   },
   "outputs": [],
   "source": [
    "x, y = gen_future_T_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2384466d-1068-4369-ab50-7aaf12267a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "m2f1pWLfPbJG"
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f64207-1855-4740-9943-9541157f9770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JJU5MRbdRDEI"
   },
   "outputs": [],
   "source": [
    "for f,fn in enumerate(['p (mbar)', 'T (degC)', 'rh (%)', 'wv (m/s)', 'wd (deg)', 'Day sin', 'Day cos', 'Year sin', 'Year cos']):\n",
    "  plt.figure(figsize=(5*(1+(f==1)), 4))\n",
    "  for s in range(10):\n",
    "    plt.plot(x[s, :, f])\n",
    "    if f==1:\n",
    "      plt.scatter(48, y[s], color=plt.gca().lines[-1].get_color())\n",
    "  plt.title(fn)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ce37287-5407-460b-ad2d-faf2b51785ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oAAjJuenj1u0"
   },
   "source": [
    "# 2. Neural Networks Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66f9db88-c892-4f29-85a1-b8e4d4e7281c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5AXSFimKkt91"
   },
   "source": [
    "## 1. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e9cb447-54ca-4f4b-94e0-b6e544f8797b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xoFa0c0Xj_6m"
   },
   "source": [
    "(Artificial) Neural network consists of layers of neurons. Artificial neuron, or perceptron, is in fact inspired by a biological neuron.\n",
    "\n",
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/Perceptron.png\" alt=\"drawing\" width=\"30%\"/>\n",
    "\n",
    "Such neuron first calculates the linear transformation of the input vector $\\bar x$:\n",
    "$$z = \\bar W \\cdot \\bar x + b = \\sum {W_i x_i} + b$$ where $\\bar W$ is vector of weights and $b$ - bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7371c72-6182-4611-8e42-e73063588d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "O7cZipYkZlH9"
   },
   "source": [
    "This is effectively linear regression. You can combine those parallely to make a multidimensional prediction, e.g.:\n",
    "\n",
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/2Perceptrons.png\" alt=\"drawing\" width=\"30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12a23c80-81b2-4ea2-b135-38682f8cd58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "C-mH0li3kzNi"
   },
   "source": [
    "## 2. Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da956b87-4ab2-432e-a381-ac44808ffb67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "i74xUp5qkxCy"
   },
   "source": [
    "Combining multiple such objects performing linear transformation sequentially would not bring any additional benefit, as the combined output would still be a linear combination of the inputs.\n",
    "\n",
    "What gives actual power to neurons, is that they additionally perform the nonlinear transformation of the result using activation function $f$ $$y = f(z)$$\n",
    "\n",
    "The most commonly used non-linear transformations are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d9e29b4-4cdd-4bb9-963e-a1370e2166d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iUo59ubLc_fi"
   },
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "  return np.clip(z, a_min=0, a_max=np.max(z))\n",
    "def SELU(z, a=1):\n",
    "  p = np.clip(z, a_min=0, a_max=np.max(z))\n",
    "  n = np.clip(z, a_min=np.min(z), a_max=0)\n",
    "  return p + (np.exp(n)-1) * a\n",
    "def LReLU(z, a=0.1):\n",
    "  return np.clip(z, a_min=0, a_max=np.max(z)) + np.clip(z, a_min=np.min(z), a_max=0) * a\n",
    "def sigmoid(z):\n",
    "  return 1/(1 + np.exp(-z))\n",
    "def step(z):\n",
    "  return np.heaviside(z, 0)\n",
    "fig, ax = plt.subplots(1, 6, figsize=(18, 3))\n",
    "z = np.linspace(-10, 10, 100)\n",
    "ax[0].plot(z, ReLU(z))\n",
    "ax[0].set_title('Rectified Linear Unit (LU)')\n",
    "ax[1].plot(z, LReLU(z))\n",
    "ax[1].set_title('Leaky Rectified LU')\n",
    "ax[2].plot(z, SELU(z))\n",
    "ax[2].set_title('Scaled Exponential LU')\n",
    "ax[3].plot(z, sigmoid(z))\n",
    "ax[3].set_title(r'$\\sigma$(z)=$\\frac{1}{1+e^z}$')\n",
    "ax[4].plot(z, np.tanh(z))\n",
    "ax[4].set_title('Hyperbolic tangent');\n",
    "ax[5].plot(z, step(z))\n",
    "ax[5].text(-6, 0.5, 'NOT USED', size=19, c='r')\n",
    "ax[5].set_title('Step function');\n",
    "for axi in ax:\n",
    "  axi.set_xlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dad3b435-b816-44d8-a0ad-5d752ad29cb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "QsEbaIujf0DV"
   },
   "source": [
    "And the reason we don't use a simple step function, is that it's everywhere either not differentiable or its derivative is zero.\n",
    "\n",
    "The last nonlinearity to mention here is *softmax*:\n",
    "$$y_i = SoftMax(\\bar z)_i = \\frac{ e^{z_i}}{\\sum_j e^{z_j}}$$\n",
    "\n",
    "While each $z_i$ can have any value, the corresponding $y_i\\in[0,1]$, and $\\sum_i y_i=1$, just like probabilities!\n",
    "\n",
    "While these $y_i$ are only pseudo-probabilities, this nonlinearity allows one to model probabilities, e.g. of a data-point belonging to a certain class.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cbbe4e3-f94d-46a2-b3ae-01f5f614de1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8QZtmo6Vk2rp"
   },
   "source": [
    "## 3. Fully connected net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c340c32f-b397-4b20-955e-9119d3bdb128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PM5z2czOc_4A"
   },
   "source": [
    "In a fully connected neural network each layer is a set of N neurons, performing different transformations of all the same layer's inputs $\\bar x = [x_i]$ producing output vector $\\bar y = [y_j]_{i=1..N}$: $$y_j = f(\\bar W_j \\cdot \\bar x + b_j)$$\n",
    "\n",
    "Since output of each layer forms input of next layer, one can write for layer $l$ (upper index denotes layer): $$x^l_j = f(\\bar W^l_j \\cdot \\bar x^{l-1} + b^l_j)$$ where $\\bar x^0$ is network's input vector.\n",
    "\n",
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/MLP.png\" alt=\"drawing\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "809e02f3-8fcc-46a3-8232-80cabee0525c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "u62hCoFbklaW"
   },
   "source": [
    "## 4. Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f6c740f-2826-4042-a8fc-16e735c35ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-58_mV6ElY5C"
   },
   "source": [
    "The last part of the puzzle is the measure of network performance, which is used to optimize the network's parameters $W^l_j$ and $b^l_j$.\n",
    "Denoting the network's output for an input $x_i$ as $\\hat y_i=\\hat y_i(x_i)$ and given the label $y_i$:\n",
    "\n",
    "1. In case of regression loss shows \"distance\" from target values:\n",
    "* L2 (MSE): $L = \\sum_i (y_i-\\hat y_i)^2$\n",
    "* L1 (MAE): $L = \\sum_i |y_i-\\hat y_i|$\n",
    "\n",
    "1. In case of classification we can use cross-entropy, which shows \"distance\" from target distribution:\n",
    "$$L = - \\sum_i \\sum_c y_{i,c} \\log(\\hat y_{i,c})$$\n",
    "Here $\\hat y_{i,c}$ - pseudo-probability of $x_i$ belonging to class $c$ and $y_{i,c}$ uses 1-hot encoding:\n",
    "\n",
    "$$y_{i,c}=\n",
    "\\begin{cases}\n",
    "    1,& \\text{if } x_i \\text{ belongs to class } c\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f08b750-e9a3-4d80-9f61-ef50f248978f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "--9TcJQ8Rahm"
   },
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "239dc21d-4f82-441a-902e-0602ece8ece0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "urF63xIfRah0"
   },
   "source": [
    "Training of neural networks is performed iteratively. The weights  $W^l_j$ and $b^l_j$ are updated on each iteration of training according to the value of the derivative of the loss function with respect to corresponding parameter:\n",
    "$$W^l_j \\rightarrow W^l_j - \\lambda \\frac{\\partial L}{\\partial W^l_j }$$\n",
    "$$b^l_j \\rightarrow b^l_j - \\lambda \\frac{\\partial L}{\\partial b^l_j },$$\n",
    "\n",
    "This is Gradient Descent optimization with learning rate $\\lambda$. The partial derivatives are calculated by the chain law, and this approach is known as [backpropagation](https://en.wikipedia.org/wiki/Backpropagation).\n",
    "\n",
    "In practice often for each iteration the loss $L$ is evaluated not on all samples, but on a sub-sample, so-called *minibatch* (sometimes - just batch). In most cases the sample order and selection for each minibatch is performed at random rendering this approach to be stochastic (thus it's called [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)). One iteration through all training data in minibatches is called *epoch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54b84ab4-2d7f-40f8-96b9-097987bf1504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "yrwaonuB4F8m"
   },
   "source": [
    "# 3. Regression with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e54bbf-1e68-48c7-a46c-bd923a5342f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05b60681-cc2f-44c1-bb02-a85296e3dca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Yj48cHUiVttY"
   },
   "source": [
    "## 1. 1D input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a854392f-e6eb-413f-93f5-da585e273373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_-SUw6f7Vwo7"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, num=1000)\n",
    "y = ((x>3)*(x<5)).astype(np.float32)\n",
    "plt.figure(figsize=(19,5))\n",
    "\n",
    "#y = x**3/500 + np.sin(x) #+ np.sin((10-x)**2)\n",
    "\n",
    "x /= 10\n",
    "x -= 0.5\n",
    "plt.plot(x, y)\n",
    "plt.plot(x[::10], y[::10],'-o')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89aad122-6902-4e26-bf0f-6910f54bfa30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "M3nmmED5WRo0"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(1,)),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation=None),\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='mae',\n",
    "              metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f18fcf13-1286-44b8-865c-569e98433bf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Z3RkZ057yEo8"
   },
   "outputs": [],
   "source": [
    "class saving_pred(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.y_preds = []\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    if epoch % 10 == 0:\n",
    "        y_p = model.predict(x).flatten()\n",
    "        #print('\\n', epoch, y_p.shape, '\\n\\n')\n",
    "        self.y_preds.append(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9a1086-42d0-4773-a96a-4bf3c6a0a0d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3Gw8BJYxWWql"
   },
   "outputs": [],
   "source": [
    "saving_callback = saving_pred()\n",
    "hist = model.fit(x, y,\n",
    "                 epochs=1000, batch_size=100, callbacks=[saving_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636e83d0-b71f-4399-bfbf-3d383d4bac27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "yLd8yWdZoJD7"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].plot(hist.epoch, hist.history['loss'])\n",
    "axs[0].set_title('loss')\n",
    "axs[1].plot(hist.epoch, hist.history['mse'])\n",
    "axs[1].set_title('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f4f1b37-51c5-4758-b163-b30f254571da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_UhGnieHWcP8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(19,5))\n",
    "y_p = model.predict(x)\n",
    "im = plt.plot(x, y_p)\n",
    "im = plt.plot(x, y, '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae0aebb4-290e-464b-8e61-9cd50f0bfcea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "t4Lh2YwDybnl"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "y_preds = saving_callback.y_preds\n",
    "\n",
    "fig = plt.figure(figsize=(19,5))\n",
    "line = plt.plot(x, y_preds[0])\n",
    "line2 = plt.plot(x, y)\n",
    "\n",
    "def animate(i):\n",
    "    y_p = y_preds[i]\n",
    "    line[0].set_data((x, y_p))\n",
    "    return line\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a799e6-ab40-4ee9-9b4c-027f9ab01286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "018674c9-464a-4b6b-978d-b248de51ad85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. House dataset with fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bdc208c-ff3b-4676-805f-2db9faacdf15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_normed = house_prices_dataset_normed(data_path='/content/data')\n",
    "x, y, df = house_prices_dataset(return_df=True, price_max=-1, area_max=-1, data_path='/content/data')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c4c0ae-25bb-423e-8ec6-b20200f938d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train the regression model and save predictions every 20 epochs\n",
    "\n",
    "class SavingPred(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_test):\n",
    "        super().__init__()\n",
    "        self.x_test = x_test\n",
    "        self.y_preds = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 2 == 0:\n",
    "            y_p = self.model.predict(self.x_test).flatten()\n",
    "            self.y_preds.append(y_p)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(x_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation=None),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='mse')\n",
    "\n",
    "saving_pred_cb = SavingPred(x_test)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[saving_pred_cb])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8490bde2-0f6f-40ee-aa9c-8a6c22285e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot training and validation RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Test loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Test RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4798c463-dda6-4e6f-8382-26c2cef4a18d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "y_preds = saving_pred_cb.y_preds\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "line, = ax.plot(y_test, y_preds[0], 'o', alpha=0.5, label='Predicted')\n",
    "ax.plot(y_test, y_test, 'r--', label='Ideal')\n",
    "\n",
    "ax.set_xlabel('True Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "title = ax.set_title('Predictions vs True Values (Epoch 0)')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    y_p = y_preds[i]\n",
    "    line.set_data((y_test, y_p))\n",
    "    title.set_text(f'Predictions vs True Values (Epoch {i*20})')\n",
    "    return line\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(y_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6864ec2c-6b88-45ea-b05e-66c63ac52ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f75746c-a68c-4cb9-a4e7-4d8b28a3412b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FCQ5wxQCgVXD"
   },
   "source": [
    "# 4. Classification of the F-MNIST dataset with neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88bdf233-1570-4ad6-a20c-5f91abc3a43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dSRc4lzeYgxX"
   },
   "source": [
    "## 0. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18b3b3b8-9dd9-45df-ad1f-f453b3483689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xM_660aCYmnS"
   },
   "source": [
    "We will create a model for classification of the F-MNIST dataset that we go acquainted with in previous sessions. We will normalize the inputs to have values $\\in[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a7e6f29-e5bb-45b7-a2ad-523270fa498a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "maLerZKejJxG"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8561905-60c2-4f43-8c98-dbef13373084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "agJ3gkg0tkTJ"
   },
   "source": [
    "## 1. Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a08049f-004d-4b0e-8c25-f99a10caecea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "D0dtcC9MZG3N"
   },
   "outputs": [],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90c80409-3349-4f52-8700-0595e2202576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cjVnBkWjZHVf"
   },
   "source": [
    "The size of each image sample $-\\; 28\\times28\\text{ pixels}\\;-\\;$ defines the input size for our neural network. Network's output - probabilities of belonging to each of the 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "752c4c29-f849-4b6e-85f2-1a95cd4728d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lPs6sljtjDUE"
   },
   "source": [
    "The following creates a 'model'. It is an object containing the neural network model itself - a simple 3-layer fully connected neural network, optimization parameters, as well as the interface for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922f5d96-c175-4906-8b1a-d2e4061816ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "cellView": "code",
    "id": "LC1SpGLbtkTL"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a51f9f5-1111-4665-a952-b7a01215adc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RFwr5MLMjxI1"
   },
   "source": [
    "Model summary provides information about the model's layers and trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40f9310-75e4-4216-b518-a9b3c13feb4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bCttp5zeb5l2"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b087a64-d602-41f9-8aee-4f1268ed0883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "P18eyAQHqZGG"
   },
   "source": [
    "## 2. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db69b63c-d515-4fa7-a71b-5ca6d9641bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VNIdb5Gtlr32"
   },
   "source": [
    "The `fit` function is the interface for model training.\n",
    "Here one can specify training and validation datasets, minibatch size, and the number of training epochs.\n",
    "\n",
    "Here during training we also save the trained models checkpoints after each epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e084a43e-520b-41d9-863c-db4e944a2fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0-OxT0aNVx-y"
   },
   "outputs": [],
   "source": [
    "save_path = 'save/mnist_{epoch}.weights.h5'\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, save_weights_only=True)\n",
    "\n",
    "hist = model.fit(x=x_train, y=y_train,\n",
    "                 epochs=50, batch_size=128,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ca4ba2b-a1c6-46a9-b404-b2fcd8021dae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8l9Gz1e4V-7Q"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].plot(hist.epoch, hist.history['loss'])\n",
    "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
    "axs[0].legend(('training loss', 'validation loss'), loc='lower right')\n",
    "axs[1].plot(hist.epoch, hist.history['accuracy'])\n",
    "axs[1].plot(hist.epoch, hist.history['val_accuracy'])\n",
    "\n",
    "axs[1].legend(('training accuracy', 'validation accuracy'), loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "351af3e9-b924-4ca1-af21-fa64667a9550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fUnlYrfaBmQ8"
   },
   "source": [
    "Current model performance can be evaluated, e.g. on the test dataset:\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6730ebf-759d-4623-b6df-6bfa27d27631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_cq_gqG4V9il"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55591c6c-87f5-4d09-8328-c9fe5ec9e386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4-5qgb0rDyj4"
   },
   "source": [
    "We can test trained model on an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "379c3078-98e3-46e2-be73-17589e0df064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "BPU8mOg2DVSO"
   },
   "outputs": [],
   "source": [
    "im_id = 0\n",
    "y_pred = model(x_test)\n",
    "\n",
    "y_pred_most_probable = np.argmax(y_pred[im_id])\n",
    "print('true lablel: ', y_test[im_id],\n",
    "      '; predicted: ',  y_pred_most_probable,\n",
    "      f'({class_names[y_pred_most_probable]})')\n",
    "plt.imshow(x_test[im_id], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c6a5d56-e64a-44e4-8382-42450677d2e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3uPb0WPTk6oq"
   },
   "source": [
    "As well as inspect on which samples does the model fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab2876c2-ba89-4e61-bb27-012861643271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "OKx-umE7R6AL"
   },
   "outputs": [],
   "source": [
    "y_pred_most_probable_all = np.argmax(y_pred, axis=1)\n",
    "wrong_pred_map = y_pred_most_probable_all!=y_test\n",
    "wrong_pred_idx = np.arange(len(wrong_pred_map))[wrong_pred_map]\n",
    "\n",
    "im_id = wrong_pred_idx[0]\n",
    "\n",
    "y_pred_most_probable = y_pred_most_probable_all[im_id]\n",
    "print('true lablel: ', y_test[im_id],\n",
    "      f'({class_names[y_test[im_id]]})',\n",
    "      '; predicted: ',  y_pred_most_probable,\n",
    "      f'({class_names[y_pred_most_probable]})')\n",
    "plt.imshow(x_test[im_id], cmap='gray');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "742b4b16-6dab-4ff0-adf8-6bca55c2f1d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HkrIXxYmqiyR"
   },
   "source": [
    "## 3. Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5f1923b-0d03-4516-b4b5-902aadfdec8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gt_BelVEdH1y"
   },
   "outputs": [],
   "source": [
    "model.load_weights('save/mnist_1.weights.h5')\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "model.load_weights('save/mnist_12.weights.h5')\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "model.load_weights('save/mnist_18.weights.h5')\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60d4b670-64b8-4dbb-a5ab-e62647ef3ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TDS71kLLmRE2"
   },
   "source": [
    "## EXERCISE 1: Train deeper network for F-MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b7c9f8f-5024-431e-a8ff-285f12cca723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8eyO5lzOmWAG"
   },
   "source": [
    "Make a deeper model, with wider layers. Remember to use the `'softmax'` activation in the last layer, as required for the classification task to encode pseudoprobabilities. In the other layers you could use `'relu'`.\n",
    "\n",
    "Try to achieve 90% accuracy.\n",
    "Does your model overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed82fb77-ac58-4082-8bb5-0d5af689ad6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8CUw7uHUxSoQ"
   },
   "outputs": [],
   "source": [
    "# 1. create model\n",
    "# 2. train the model\n",
    "# 3. plot the loss and accuracy evolution during training\n",
    "# 4. evaluate model in best point (before overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec1f0ce1-b84f-4612-979d-b443799c3cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "CWm4FgSu-tK0"
   },
   "source": [
    "# 5. Extras and Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0287da4e-b3ee-4886-bc89-276298fe445b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "OReFhRTHxCdl"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/cheatsheet.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa425c10-489f-4209-964a-1d21b6ef05fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_65g5ZdTxCdm"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/clusters.png\" width=\"100%\"/>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Course_4",
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [
    "LzEnLAMt3De2",
    "pclZR6uFklf_",
    "8UQgU5I-lEll",
    "FJ5rjq7fIe8Q",
    "q7CNxkPdNB4L",
    "8S1jwU4cXQX4",
    "ITfbaOgfYNsq",
    "x2NWxK0BFwyw",
    "oAAjJuenj1u0",
    "5AXSFimKkt91",
    "C-mH0li3kzNi",
    "8QZtmo6Vk2rp",
    "u62hCoFbklaW",
    "--9TcJQ8Rahm",
    "yrwaonuB4F8m",
    "Yj48cHUiVttY",
    "2PFZcbkbVprF",
    "FCQ5wxQCgVXD",
    "dSRc4lzeYgxX",
    "agJ3gkg0tkTJ",
    "CWm4FgSu-tK0"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-m1-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
