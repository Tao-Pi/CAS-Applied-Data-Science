{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92cf5540-e29c-46db-a4fa-22956b4a9a7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1oZByfpftmcT"
   },
   "source": [
    "# Tutorial IV: Convolutions in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74926694-92d7-4d66-b239-bd88a5eda0a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "N__G0gDAtmcU"
   },
   "source": [
    "<p>\n",
    "Bern Winter School on Machine Learning, 2024<br>\n",
    "Prepared by Mykhailo Vladymyrov and Matthew Vowels.\n",
    "</p>\n",
    "\n",
    "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fcc2eca-f66e-4bdb-ab36-eddb3075f47d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "knW3JBEDtmcU"
   },
   "source": [
    "In this session we will look at the convolution operation and try to build some intuition about it.\n",
    "Also we will look at one of the state-of-the art deep models, [Inception](https://arxiv.org/abs/1602.07261). It is designed to perform image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "604171c6-c176-4a30-a04e-3147eeb877ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "l7s9QvYetmcY"
   },
   "source": [
    "## 1. Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d5bb0e-f77f-47f0-a5cd-f9226f2bad6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5P-pLWxURfCY"
   },
   "outputs": [],
   "source": [
    "colab = False # set to True is using google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87aac05d-3de1-4a16-b513-0482780e5e26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run line below on first execution\n",
    "# %pip install torch\n",
    "# %pip install --upgrade typing_extensions\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:35:31.047344600Z",
     "start_time": "2024-01-03T16:35:30.636179400Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dceec87-9fbd-4452-9a96-cd1750ddff2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cjsvvAJatmcY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.hub import download_url_to_file\n",
    "from torchvision import transforms\n",
    "\n",
    "from scipy.ndimage import rotate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79937312-2dc6-42fc-b816-dfc7aaf6265f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "id": "uOY0lBz4qLw3"
   },
   "source": [
    "### Download libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-03T16:23:59.894990500Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b7a3f3b-52a7-4014-b814-2da995e480ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xy42xYOqLw4",
    "outputId": "24af7cc3-5411-497a-d547-0b50589e8d29"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    path = os.path.join(os.path.abspath('.')+'material.tgz')\n",
    "    url = 'https://github.com/neworldemancer/BMLWS/raw/main/tut_files/tpub0320.tgz'\n",
    "    # p = tf.keras.utils.get_file(path, url)\n",
    "    # Download compressed file with torch utils\n",
    "\n",
    "    download_url_to_file(url=url, dst=path)\n",
    "\n",
    "    tar = tarfile.open(path, \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3436eb1f-dd99-4d7b-b0b4-b9232a4a2f7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uwVORI1Vtmca"
   },
   "source": [
    "## 3. Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3500a138-edf8-4055-8c4f-ce361a5a6874",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "o0i6LmfYtmcb"
   },
   "source": [
    "In fully connected network all inputs of a layer are connected to all neurons of the following layer:\n",
    "<tr>\n",
    "    <td> <img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/Perceptron.png\" alt=\"drawing\" width=\"30%\"/></td>\n",
    "    <td> <img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/MLP.png\" alt=\"drawing\" width=\"50%\"/></td>\n",
    "</tr>\n",
    "<br>In convolutional nets the same holds for each neighbourhood, and the weights are shared:<br>\n",
    "<img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/CNN1.png\" alt=\"drawing\" width=\"50%\"/><br>\n",
    "<img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/CNN2.png\" alt=\"drawing\" width=\"50%\"/><br>\n",
    "<img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/CNN3.png\" alt=\"drawing\" width=\"50%\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27df41de-479a-4177-b5a0-c0bdfaaa2c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "D_nODHgbtmcb"
   },
   "source": [
    "Let's see what a convolution is, and how it behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48601d93-b2b8-46f2-92d3-f3e909d836b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IKnDJ7lcNNsL"
   },
   "source": [
    "### 1.1. Handkrafting filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:31:28.996279500Z",
     "start_time": "2024-01-03T16:31:27.570383500Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "754448ee-bdfd-45f4-8b81-29a40cef8e25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "dH2IPjiftmcc",
    "outputId": "d0536d4e-66f3-40ca-a986-94e2fd7a80d6"
   },
   "outputs": [],
   "source": [
    "#load image, convert to gray-scale and normalize\n",
    "img_raw = plt.imread('ML3/chelsea.jpg')  # load RGB image (HWC)\n",
    "img_raw = img_raw.mean(axis=2)  # convert to gray-scale by averaging over color channels\n",
    "img_raw = img_raw[-256:, 100:356]  # crop to 256x256 pixels\n",
    "img_raw = img_raw.astype(np.float32)  # convert to float32\n",
    "img_raw = (img_raw-img_raw.mean())/img_raw.std()  # normalize to zero mean and unit variance\n",
    "\n",
    "plt.imshow(img_raw, cmap='gray')  # show image\n",
    "plt.grid(False)  # disable grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9778f4d4-b93c-4def-8315-c6d6f98ab82b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZMbar3LTqLw-"
   },
   "outputs": [],
   "source": [
    "def conv_2d(x, flt):\n",
    "    # x: B, C, H, W\n",
    "    # flt: Co, Ci, Hf, Wf\n",
    "    return F.conv2d(input=x, weight=flt, stride=1, padding=0, dilation=1)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x, flt):\n",
    "        print(x.shape, flt.shape)\n",
    "        y1 = conv_2d(x, flt)\n",
    "        y2 = conv_2d(y1, flt)\n",
    "        y3 = conv_2d(y2, flt)\n",
    "        y4 = conv_2d(y3, flt)\n",
    "        return x, y1, y2, y3, y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "205c74ab-8754-47fa-9faa-4101bf9adfc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xGy1xs-DqLw-"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59bfc911-e41b-4b8f-b62a-5655431c59e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "G9qyViZCqLw_"
   },
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7ec3b17-b1b0-4357-b6f6-e8fd39c618ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "T6xwFvEbtxty"
   },
   "source": [
    "In the following, we define a function that applies a convolution operation to an input image using a filter. It prepares the image and filter by adding batch and channel dimensions, converts them into PyTorch tensors, and processes them through a given model. The resulting convolved outputs are returned as NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c98e6567-700d-4a41-8431-3314c0c1286e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "K9dOPYUAJBJj"
   },
   "outputs": [],
   "source": [
    "def get_convolved(img, flt):\n",
    "    img_raw4d = img[np.newaxis,np.newaxis] # add batch (1) and channel (1) dimensions\n",
    "\n",
    "    flt_mtx_np = np.array(flt, np.float32)\n",
    "    flt_mtx_np = flt_mtx_np[np.newaxis, np.newaxis] # add N channels out (1) and N channels in (1) dimensions\n",
    "\n",
    "    img_raw4d_t = torch.from_numpy(img_raw4d).to(device)\n",
    "    flt_mtx_t = torch.from_numpy(flt_mtx_np).to(device)\n",
    "\n",
    "    res = model(img_raw4d_t, flt_mtx_t)\n",
    "    res = [r.detach().cpu().numpy() for r in res]  # disable gradient tracking, move to cpu, convert to numpy\n",
    "    res = [r[0,0] for r in res]  # remove batch and channel dimensions, only one channel in the output\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d5c4999-a0e1-4246-8257-9b9b33858d41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8s8-jwn3YDpd"
   },
   "source": [
    "Let's experiment with filter kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f22233a-8c41-4dcd-94b0-27ae32b3436f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "v17s7CUhMlQz",
    "outputId": "76daf96d-06f1-4be6-bd9c-a50abf84b184"
   },
   "outputs": [],
   "source": [
    "flt_mtx = [\n",
    "    [ 0, 0, 0, 0, 0,],\n",
    "    [ 0, 0, 0, 0, 0,],\n",
    "    [ 0, 0, 1, 0, 0,],\n",
    "    [ 0, 0, 0, 0, 0,],\n",
    "    [ 0, 0, 0, 0, 0,],\n",
    "] # identity transformation\n",
    "\n",
    "ims_convolved = get_convolved(img_raw, flt_mtx)\n",
    "\n",
    "n = len(ims_convolved)\n",
    "fig, ax = plt.subplots(1, n+1, figsize=(n*4, 4))\n",
    "for col in range(n):\n",
    "    ax[col].imshow(ims_convolved[col], cmap='gray')  #, vmin=-3, vmax=3\n",
    "    ax[col].grid(False)\n",
    "    ax[col].set_title('conv %d'% col if col else 'raw')\n",
    "\n",
    "ax[n].imshow(flt_mtx, cmap='gray')\n",
    "ax[n].grid(False)\n",
    "_=ax[n].set_title('filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3f3e33e-128b-43a0-bd9a-6b3245dff5ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "id": "GnhuLvFbqLxB"
   },
   "source": [
    "1. experiment with different filters and understand what they do, e.g.:<br>\n",
    "- identity transformation\n",
    "- identity transformation with positive non-unit values\n",
    "- identity transformation with negative unit value\n",
    "- identity transformation off center\n",
    "- blurring with box filter\n",
    "- edge detection with + and - bands\n",
    "- try whatever you like\n",
    "\n",
    "2. experiment with convolution parameters: <br>\n",
    "- padding = 1, 2, 3\n",
    "- stride = 2\n",
    "- dilation = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3720ffdb-8ede-48cc-8213-4e692d419fba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "57iJW9YGNk1m"
   },
   "source": [
    "### 1.2. Most common filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de226ade-a771-418f-9273-9f341b015c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JtrTJpS6NvnZ"
   },
   "source": [
    "Here are most common filter kernels, in 1D:\n",
    "\n",
    "|filter type| effect|\n",
    "|-----|-----|\n",
    "|gaussian| bluring|\n",
    "|first derivative of gaussian|detection of edges|\n",
    "|second derivative of gaussian|detection of peaks|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19e5f2df-64d1-4241-a36c-f0ffdb7758b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Van15HojduYJ"
   },
   "outputs": [],
   "source": [
    "def gaussian(n=5):\n",
    "    x = np.linspace(-3, 3, n)\n",
    "    y = np.exp(-x**2 * 0.5) / np.sqrt(2*np.pi)\n",
    "    return y\n",
    "\n",
    "def dgaussian(n=5):\n",
    "    x = np.linspace(-3, 3, n)\n",
    "    y = - 2 * x * np.exp(-x**2 * 0.5) / np.sqrt(2*np.pi)\n",
    "    return y\n",
    "\n",
    "def ddgaussian(n=5):\n",
    "    x = np.linspace(-3, 3, n)\n",
    "    y = - 2 * (2*x**2 - 1) * np.exp(-x**2 * 0.5) / np.sqrt(2*np.pi)\n",
    "    return y\n",
    "\n",
    "def ddgaussian2d(n=5):\n",
    "    c = np.linspace(-3, 3, n)\n",
    "    r = np.asarray([[np.sqrt(xi**2+yi**2) for xi in c] for yi in c])\n",
    "    f = lambda x: (- 2 * (2*x**2 - 1) * np.exp(-x**2 * 0.5) / np.sqrt(2*np.pi))\n",
    "\n",
    "    y = f(r)\n",
    "    y -= y.mean()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84149724-803b-4acd-a26d-93513076ca98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZW-6M45SvB3Q"
   },
   "source": [
    "We plot them :\n",
    "*   gaussian(n): A Gaussian function defined over n points.\n",
    "*   dgaussian(n): The first derivative of the Gaussian function.\n",
    "*   ddgaussian(n): The second derivative of the Gaussian function.\n",
    "*   ddgaussian2d(n): A 2D second derivative (likely for visualization or further operations).\n",
    "*   rf2d: A lambda function to generate random 2D normal noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca292501-ba6d-45f8-9777-4862bcd2850d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "OljkMi3jgkh1",
    "outputId": "edcc8aad-875e-4016-f275-8d5f625ed00e"
   },
   "outputs": [],
   "source": [
    "n = 30\n",
    "\n",
    "gf = np.tile(gaussian(n)[np.newaxis], [n, 1])\n",
    "\n",
    "dgf = np.tile(dgaussian(n)[np.newaxis], [n, 1])\n",
    "\n",
    "ddgf = ddgaussian(n)\n",
    "ddgf -= ddgf.mean()\n",
    "ddgf = np.tile(ddgf[np.newaxis], [n, 1])\n",
    "\n",
    "ddgf2d = ddgaussian2d(n)\n",
    "rf2d = lambda:  np.random.normal(size=(5,5))\n",
    "\n",
    "\n",
    "plt.plot(gf[0], label=r'$g(x)$')\n",
    "plt.plot(dgf[0], label=r'$d g(x)/dx$')\n",
    "plt.plot(ddgf[0], label=r'$d^2 g(x)/dx^2$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbb7aa4a-ecc7-4961-b2d7-9dc5671769ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "CVijKz5txQh7"
   },
   "source": [
    "Let's create and visualize the filter matrix based on a 1D Gaussian function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d875ea4-dc04-4ea3-83ae-e0e6e4cc9d19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "-wlTUAf60RXF",
    "outputId": "63f560c1-c072-4641-db12-a38280f595ed"
   },
   "outputs": [],
   "source": [
    "flt_mtx = gf*gf.transpose()\n",
    "\n",
    "#flt_mtx = rotate(flt_mtx, 30, reshape=False)\n",
    "\n",
    "plt.imshow(flt_mtx)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f4f705-e3cb-4be5-a820-f2cdbd18a098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "ZiNvmAMkMuSr",
    "outputId": "a42fec6e-abd6-425d-8296-23568b5223e3"
   },
   "outputs": [],
   "source": [
    "flt_mtx = gf*gf.transpose()    # gaussian filter\n",
    "#flt_mtx = dgf*gf.transpose()   # gabor filter, 1st derivative of gaussian (edge detection)\n",
    "#flt_mtx = ddgf*gf.transpose()  # 2nd derivative of gaussian (line detection)\n",
    "#flt_mtx = ddgf2d               # 2nd derivative of gaussian, central symmetric, (spot detection)\n",
    "\n",
    "#flt_mtx = rotate(flt_mtx, 45, reshape=False)\n",
    "\n",
    "ims_convolved = get_convolved(img_raw, flt_mtx)\n",
    "\n",
    "n = len(ims_convolved)\n",
    "fig, ax = plt.subplots(1, n+1, figsize=(n*4, 4))\n",
    "for col in range(n):\n",
    "    ax[col].imshow(ims_convolved[col], cmap='gray')  #, vmin=-3, vmax=3\n",
    "    ax[col].grid(False)\n",
    "    ax[col].set_title('conv %d'% col if col else 'raw')\n",
    "\n",
    "ax[n].imshow(flt_mtx, cmap='gray')\n",
    "ax[n].grid(False)\n",
    "_=ax[n].set_title('filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d7eedd8-14f2-4e03-94e2-755ef10e5a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-QoRTghDYLDX"
   },
   "source": [
    "## 4. Exercise 20 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421fd6dd-df9c-41c3-a849-8732a3081d3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YgcLuCrNYOLV"
   },
   "source": [
    "Experiment with filters, try random, try to amplify some specific pattern eg whiskers or pupil, or perhaps make animation of filter effect depending on some parameter - e.g. size, angle, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41db7ac5-11ed-4f45-bf70-82fb58f3ed83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "UPrth-Ertmck"
   },
   "source": [
    "## 5. Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2441cdc-b5a9-417b-902a-ee5c3cfd6531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5yzrNhX2ZPGf"
   },
   "source": [
    "Let's check some pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:49:52.644544900Z",
     "start_time": "2024-01-03T16:49:21.600292400Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df91be9-4041-4a95-8a0d-a82d17699010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6G25jyJiIVV",
    "outputId": "6911a449-8270-488c-efe2-5de76db38998"
   },
   "outputs": [],
   "source": [
    "# load a pretrained inception v3 model from torchhub\n",
    "base_model = torch.hub.load('pytorch/vision:v0.7.0', 'inception_v3', pretrained=True)\n",
    "base_model.eval()\n",
    "\n",
    "download_url_to_file(url='https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt', dst='imagenet_classes.txt')\n",
    "\n",
    "with open('imagenet_classes.txt') as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e12bfa05-f8ab-46f1-bfd3-643915921371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FPzKLLPitmcr"
   },
   "source": [
    "## 6. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd5c230e-af66-422c-8f63-3b13dc023d7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "QJIfPj7Wtmcs"
   },
   "source": [
    "We will use one image to check model. `img_preproc` is croped to 299x299 pixels and slightly transformed to be used as imput for the model using `inception.prepare_training_img`. `inception.training_img_to_display` is then used to convert it to displayable one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:32:44.573044800Z",
     "start_time": "2024-01-03T16:32:44.037549300Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9f2a594-6210-44ae-9506-9817dde20718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "BZbVMgx0qLxS",
    "outputId": "a49ac8ea-e375-4f25-a68a-3e12138a17a7"
   },
   "outputs": [],
   "source": [
    "sz = 299\n",
    "img_raw = plt.imread('ML3/chelsea.jpg')\n",
    "\n",
    "img_crop = img_raw.copy()[:sz, 100:100+sz]\n",
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].imshow(img_raw)\n",
    "axs[0].grid(False)\n",
    "axs[1].imshow(img_crop)\n",
    "axs[1].grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c44405a2-a64a-467c-b901-5d287f64c058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DLpxv4yKS-3a"
   },
   "source": [
    "We need to apply same scaling to the input asa was done for training samples. This is done with a `preprocess_input` method corresponding to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:35:50.914697600Z",
     "start_time": "2024-01-03T16:35:50.618577700Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4708552-92ee-486b-8046-6602d6818ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5VAk6CcqLxT",
    "outputId": "c1f017b4-67c2-4c16-e220-66f45177bd29"
   },
   "outputs": [],
   "source": [
    "image_chw = img_crop.transpose([2,0,1])\n",
    "image_chw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:39:47.817240900Z",
     "start_time": "2024-01-03T16:39:47.415061500Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "853fc837-4651-4806-a0cb-1e03126c8ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "sh3hyt70qLxT"
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # nor,malizsation as trianing data (std on ImageNet trainign set)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:39:48.216221200Z",
     "start_time": "2024-01-03T16:39:47.804240Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81fd3cdb-f03c-4edb-9eb0-5746e48bcfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vu9pcwRAqLxT",
    "outputId": "5bfb981e-40e1-420d-e38d-f61ac88febb8"
   },
   "outputs": [],
   "source": [
    "image_t = preprocess(img_crop)  # hwc -> chw\n",
    "image_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:41:04.950182500Z",
     "start_time": "2024-01-03T16:41:04.446430400Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb04c01-1248-4eac-b6bd-4ed8c9efe952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmP4oiTSqLxU",
    "outputId": "492de023-e119-45ec-e7f2-7cfcbdc61bc5"
   },
   "outputs": [],
   "source": [
    "image_t_bchw = image_t.unsqueeze(0)  # add batch dimension\n",
    "image_t_bchw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:00:02.473036500Z",
     "start_time": "2024-01-03T17:00:01.337542300Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e30668b-6b9c-4792-bcb0-5eee60f50493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnUwgRmpqLxU",
    "outputId": "f50aa367-98f2-49e5-decd-419e0a00f738"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    probs = base_model(image_t_bchw)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1a47ecf-e357-4f91-af2f-76e7e250427e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7Rhw6ovNy5Gy"
   },
   "source": [
    "For the prediction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:00:02.559601800Z",
     "start_time": "2024-01-03T17:00:01.860763500Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "940bd75c-5442-44b9-8e1a-b631fbc9a8af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vjzR-1xrqLxU"
   },
   "outputs": [],
   "source": [
    "probs = F.softmax(probs, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:00:03.052598800Z",
     "start_time": "2024-01-03T17:00:02.451036700Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73311e13-39da-478f-84fd-48c4cf40afc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pVW5Y30wqLxU"
   },
   "outputs": [],
   "source": [
    "# get top 5 predictions\n",
    "top5 = torch.topk(probs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:00:05.436093700Z",
     "start_time": "2024-01-03T17:00:05.322502600Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2944617f-1550-4772-87b1-3d380a89a98c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jQnuIwj_qLxV"
   },
   "outputs": [],
   "source": [
    "indices = top5.indices\n",
    "probs5 = top5.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:00:06.449480700Z",
     "start_time": "2024-01-03T17:00:05.748946900Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dc2c9e3-ad6e-4cf1-8484-4999effb79b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpQFyTLvqLxV",
    "outputId": "8fc71aa7-e864-4549-c769-223aff60c481"
   },
   "outputs": [],
   "source": [
    "[class_names[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:00:07.390738800Z",
     "start_time": "2024-01-03T17:00:07.169981700Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a2d9bfb-4d35-4ce2-b564-62a5f1a56a6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exoswB3TqLxV",
    "outputId": "04224081-0ee5-46a0-8f68-73ca63f84d06"
   },
   "outputs": [],
   "source": [
    "[f'{p:.5f}' for p in probs5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T17:01:40.358150700Z",
     "start_time": "2024-01-03T17:01:36.618263200Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e94cf2a4-47fa-489a-850b-87fff6f5db6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "tL3fFVrrTmeM",
    "outputId": "ed1b536a-3c25-4c8a-b98f-4cba720f9b42"
   },
   "outputs": [],
   "source": [
    "probs_np = probs.detach().cpu().numpy()\n",
    "indices = np.argsort(probs_np)[::-1][:100]\n",
    "probs_s = probs_np[indices]\n",
    "classes = [class_names[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.semilogy(classes, probs_s, '.');\n",
    "plt.xticks(rotation=90);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Tutorial_IV_torch_Convolutions",
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [
    "l7s9QvYetmcY",
    "150iJZcmZlQW",
    "zljWXlXquHgp"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
