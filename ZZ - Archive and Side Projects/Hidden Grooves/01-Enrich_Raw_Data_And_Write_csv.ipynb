{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a93d8eba-d6b7-427f-8bfe-013fd11aae28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Discogs Data Enrichment Notebook\n",
    "\n",
    "This notebook demonstrates how to work with the Discogs data dump, available at [Discogs Data Dumps](https://discogs-data-dumps.s3.us-west-2.amazonaws.com/index.html). The data consists of large compressed XML files (up to 10GB each), and not all possible data is present in the dump.\n",
    "\n",
    "**Workflow:**\n",
    "- Download and unpack the relevant XML data files.\n",
    "- Parse the XML to extract release records.\n",
    "- Use the Discogs API to enrich each record with additional information, such as price, demand (people asking), and supply (people offering).\n",
    "- Save the enriched results as a CSV file, formatted for easy use in Jupyter notebooks and collaborative workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15ec6698-4457-401a-ac9d-eab716fba61b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Download and unpack the relevant XML data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cdbaf6e-fcdf-4f09-b9b1-9033e39eafe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE VOLUME IF NOT EXISTS swi_audience_prd.discogs.raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c411412-0480-4bf6-a0ff-400737decef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "mkdir -p /Volumes/swi_audience_prd/discogs/raw\n",
    "ls -lh /Volumes/swi_audience_prd/discogs/raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a144ebc-fbf2-425c-9532-5b872ee8e5c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "which aria2c || echo \"aria2c nicht gefunden (ok, dann wget nutzen)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29c2d5cd-ef59-4492-b60f-b33dd787b452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "URL=\"https://discogs-data-dumps.s3.us-west-2.amazonaws.com/data/2025/discogs_20251201_releases.xml.gz\"\n",
    "OUT=\"/Volumes/swi_audience_prd/discogs/raw/discogs_20251201_releases.xml.gz\"\n",
    "\n",
    "wget -c -O \"$OUT\" \"$URL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b60cc22-d7e3-4414-bb13-ecacfbbe94dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 64 * 1024 * 1024)  # 64MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8afe5ebe-cb2f-4c96-86e6-6d111eb9df2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "SRC=\"/Volumes/swi_audience_prd/discogs/raw/discogs_20251201_releases.xml.gz\"\n",
    "DST=\"/Volumes/swi_audience_prd/discogs/raw/discogs_20251201_releases.xml\"\n",
    "\n",
    "# falls schon vorhanden, nicht nochmal machen:\n",
    "if [ ! -f \"$DST\" ]; then\n",
    "  gunzip -c \"$SRC\" > \"$DST\"\n",
    "fi\n",
    "\n",
    "ls -lh \"$SRC\" \"$DST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "042a6cc0-b372-4e18-bd5e-fee9ef54d28b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mehr Parallelität & weniger \"Monster\"-Partitions\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 64 * 1024 * 1024)  # 64MB\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 2000)                   # je nach cluster, lieber hoch\n",
    "\n",
    "# XML parsing ist CPU lastig: AQE hilft nicht immer, kann aber helfen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "122d0722-5985-494e-b32c-e12745635743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parse the XML to extract release records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e4c394-c6b9-4bde-a5b2-b31ebd5618f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path_xml = \"/Volumes/swi_audience_prd/discogs/raw/discogs_20251201_releases.xml\"\n",
    "\n",
    "df_raw = (\n",
    "    spark.read.format(\"xml\")\n",
    "    .option(\"rowTag\", \"release\")\n",
    "    # optional, falls Probleme:\n",
    "    # .option(\"inferSchema\", \"false\")\n",
    "    # .option(\"samplingRatio\", 0.01)\n",
    "    .load(path_xml)\n",
    ")\n",
    "\n",
    "# Direkt schreiben (Bronze Delta) – ohne Anzeige\n",
    "(df_raw\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .saveAsTable(\"swi_audience_prd.discogs.releases_bronze_delta\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e8c90d-e7b1-4da0-9e57-30d145c243d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_bronze = spark.table(\"swi_audience_prd.discogs.releases_bronze_delta\")\n",
    "\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "df_vinyl = df_bronze.filter(\n",
    "    expr(\"exists(formats.format, x -> x._name = 'Vinyl')\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "138092fe-6487-4f67-8b3d-076c73fb872b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vinyl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef7e8e93-8c88-4b7f-9ea1-69170d17e3b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_ids = (\n",
    "    df_vinyl\n",
    "    .select(F.col(\"_id\").cast(\"long\").alias(\"release_id\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "df_ids.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\n",
    "    \"swi_audience_prd.discogs.vinyl_release_ids\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "888924d5-073f-478b-9295-ec9c7271ecd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Use the Discogs API to enrich each record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae91aa66-41da-40c6-8ed0-a2ec201e8bee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "TOKEN = \"IRHdEbtSbNGcCnJFgyjIxhVcEqWwsQbYAfGJGolW\"  # generiert auf https://www.discogs.com/de/settings/developers\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Discogs token={TOKEN}\",\n",
    "    \"User-Agent\": \"swi-audience-prd-discogs/1.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a10c7c16-77ef-4f2f-9089-76e403907b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    LongType, IntegerType, DoubleType, StringType, BooleanType, TimestampType\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "number_of_releases_to_fetch = 10000  # starte klein, dann erhöhen\n",
    "CURRENCY = \"CHF\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helpers\n",
    "# ------------------------------------------------------------\n",
    "def _to_json_str(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    try:\n",
    "        return json.dumps(x, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "def _to_bool(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in (\"true\", \"1\", \"yes\", \"y\")\n",
    "    if isinstance(x, (int, float)):\n",
    "        return bool(x)\n",
    "    return None\n",
    "\n",
    "def _to_int(x):\n",
    "    try:\n",
    "        return int(x) if x is not None else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _to_float(x):\n",
    "    try:\n",
    "        return float(x) if x is not None else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _to_ts(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    try:\n",
    "        s = str(x).replace(\"Z\", \"+00:00\")\n",
    "        return datetime.fromisoformat(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# HTTP helper with retry (now supports params)\n",
    "# ------------------------------------------------------------\n",
    "def get_with_retry(url: str, params: dict = None, max_tries: int = 6, base_sleep: float = 1.2):\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_tries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, params=params, timeout=30)\n",
    "\n",
    "            # Rate limit\n",
    "            if r.status_code == 429:\n",
    "                retry_after = r.headers.get(\"Retry-After\")\n",
    "                sleep_s = float(retry_after) if retry_after else (base_sleep * attempt)\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(base_sleep * attempt)\n",
    "\n",
    "    raise RuntimeError(f\"Failed after {max_tries} tries: {url} / last_err={last_err}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main fetch: releases + marketplace stats (separate endpoint!)\n",
    "# ------------------------------------------------------------\n",
    "def fetch_release_full(release_id: int, curr_abbr: str = \"CHF\") -> dict:\n",
    "    # A) Release endpoint\n",
    "    url_rel = f\"https://api.discogs.com/releases/{release_id}\"\n",
    "    j = get_with_retry(url_rel).json()\n",
    "\n",
    "    community = j.get(\"community\") or {}\n",
    "    rating = (community.get(\"rating\") or {})\n",
    "    submitter = (community.get(\"submitter\") or {})\n",
    "\n",
    "    # B) Marketplace stats endpoint (reliable source for num_for_sale/lowest_price/blocked)\n",
    "    url_m = f\"https://api.discogs.com/marketplace/stats/{release_id}\"\n",
    "    jm = get_with_retry(url_m, params={\"curr_abbr\": curr_abbr}).json()\n",
    "\n",
    "    # Marketplace parsing\n",
    "    num_for_sale = _to_int(jm.get(\"num_for_sale\"))\n",
    "    blocked_from_sale = _to_bool(jm.get(\"blocked_from_sale\"))\n",
    "\n",
    "    lowest_value = None\n",
    "    lowest_currency = None\n",
    "    lowest = jm.get(\"lowest_price\")\n",
    "    if isinstance(lowest, dict):\n",
    "        lowest_value = _to_float(lowest.get(\"value\"))\n",
    "        lowest_currency = lowest.get(\"currency\")\n",
    "    elif lowest is not None:\n",
    "        lowest_value = _to_float(lowest)\n",
    "        lowest_currency = curr_abbr\n",
    "\n",
    "    row = {\n",
    "        # identifiers / basic\n",
    "        \"release_id\": _to_int(j.get(\"id\", release_id)),\n",
    "        \"status\": j.get(\"status\"),\n",
    "        \"year\": _to_int(j.get(\"year\")),\n",
    "        \"data_quality\": j.get(\"data_quality\"),\n",
    "        \"resource_url\": j.get(\"resource_url\"),\n",
    "        \"uri\": j.get(\"uri\"),\n",
    "\n",
    "        # main metadata\n",
    "        \"title\": j.get(\"title\"),\n",
    "        \"country\": j.get(\"country\"),\n",
    "        \"released\": j.get(\"released\"),\n",
    "        \"released_formatted\": j.get(\"released_formatted\"),\n",
    "        \"notes\": j.get(\"notes\"),\n",
    "        \"artists_sort\": j.get(\"artists_sort\"),\n",
    "\n",
    "        # master\n",
    "        \"master_id\": _to_int(j.get(\"master_id\")),\n",
    "        \"master_url\": j.get(\"master_url\"),\n",
    "\n",
    "        # marketplace (NOW from /marketplace/stats)\n",
    "        \"num_for_sale\": num_for_sale,\n",
    "        \"lowest_price_value\": lowest_value,\n",
    "        \"lowest_price_currency\": lowest_currency,\n",
    "        \"blocked_from_sale\": blocked_from_sale,\n",
    "\n",
    "        # timestamps\n",
    "        \"date_added_ts\": _to_ts(j.get(\"date_added\")),\n",
    "        \"date_changed_ts\": _to_ts(j.get(\"date_changed\")),\n",
    "\n",
    "        # community metrics\n",
    "        \"have\": _to_int(community.get(\"have\")),\n",
    "        \"want\": _to_int(community.get(\"want\")),\n",
    "        \"rating_count\": _to_int(rating.get(\"count\")),\n",
    "        \"rating_average\": _to_float(rating.get(\"average\")),\n",
    "        \"submitter_username\": submitter.get(\"username\"),\n",
    "        \"submitter_resource_url\": submitter.get(\"resource_url\"),\n",
    "\n",
    "        # small “thumb” convenience\n",
    "        \"thumb\": j.get(\"thumb\"),\n",
    "\n",
    "        # nested fields as JSON strings (robust)\n",
    "        \"artists_json\": _to_json_str(j.get(\"artists\")),\n",
    "        \"labels_json\": _to_json_str(j.get(\"labels\")),\n",
    "        \"companies_json\": _to_json_str(j.get(\"companies\")),\n",
    "        \"formats_json\": _to_json_str(j.get(\"formats\")),\n",
    "        \"identifiers_json\": _to_json_str(j.get(\"identifiers\")),\n",
    "        \"genres_json\": _to_json_str(j.get(\"genres\")),\n",
    "        \"styles_json\": _to_json_str(j.get(\"styles\")),\n",
    "        \"tracklist_json\": _to_json_str(j.get(\"tracklist\")),\n",
    "        \"videos_json\": _to_json_str(j.get(\"videos\")),\n",
    "        \"images_json\": _to_json_str(j.get(\"images\")),\n",
    "        \"extraartists_json\": _to_json_str(j.get(\"extraartists\")),\n",
    "        \"community_contributors_json\": _to_json_str(community.get(\"contributors\")),\n",
    "\n",
    "        \"error\": None,\n",
    "    }\n",
    "    return row\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# IDs holen aus deinem df_vinyl (du hast _id)\n",
    "# ------------------------------------------------------------\n",
    "N = number_of_releases_to_fetch\n",
    "ids = (\n",
    "    df_vinyl\n",
    "    .select(F.col(\"_id\").cast(\"long\").alias(\"release_id\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    "    .limit(N)\n",
    "    .toPandas()[\"release_id\"]\n",
    "    .astype(int)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Fetch loop (throttle)\n",
    "# ------------------------------------------------------------\n",
    "rows = []\n",
    "for i, rid in enumerate(ids, start=1):\n",
    "    try:\n",
    "        rows.append(fetch_release_full(rid, curr_abbr=CURRENCY))\n",
    "    except Exception as e:\n",
    "        rows.append({\n",
    "            \"release_id\": int(rid),\n",
    "            \"status\": None,\n",
    "            \"year\": None,\n",
    "            \"data_quality\": None,\n",
    "            \"resource_url\": None,\n",
    "            \"uri\": None,\n",
    "            \"title\": None,\n",
    "            \"country\": None,\n",
    "            \"released\": None,\n",
    "            \"released_formatted\": None,\n",
    "            \"notes\": None,\n",
    "            \"artists_sort\": None,\n",
    "            \"master_id\": None,\n",
    "            \"master_url\": None,\n",
    "            \"num_for_sale\": None,\n",
    "            \"lowest_price_value\": None,\n",
    "            \"lowest_price_currency\": None,\n",
    "            \"blocked_from_sale\": None,\n",
    "            \"date_added_ts\": None,\n",
    "            \"date_changed_ts\": None,\n",
    "            \"have\": None,\n",
    "            \"want\": None,\n",
    "            \"rating_count\": None,\n",
    "            \"rating_average\": None,\n",
    "            \"submitter_username\": None,\n",
    "            \"submitter_resource_url\": None,\n",
    "            \"thumb\": None,\n",
    "            \"artists_json\": None,\n",
    "            \"labels_json\": None,\n",
    "            \"companies_json\": None,\n",
    "            \"formats_json\": None,\n",
    "            \"identifiers_json\": None,\n",
    "            \"genres_json\": None,\n",
    "            \"styles_json\": None,\n",
    "            \"tracklist_json\": None,\n",
    "            \"videos_json\": None,\n",
    "            \"images_json\": None,\n",
    "            \"extraartists_json\": None,\n",
    "            \"community_contributors_json\": None,\n",
    "            \"error\": str(e),\n",
    "        })\n",
    "\n",
    "    time.sleep(1.2)  # konservativ gegen Rate Limit\n",
    "    if i % 200 == 0:\n",
    "        print(f\"{i}/{len(ids)} done\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Explizites Schema (wie gehabt)\n",
    "# ------------------------------------------------------------\n",
    "schema = StructType([\n",
    "    StructField(\"release_id\", LongType(), False),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"data_quality\", StringType(), True),\n",
    "    StructField(\"resource_url\", StringType(), True),\n",
    "    StructField(\"uri\", StringType(), True),\n",
    "\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"released\", StringType(), True),\n",
    "    StructField(\"released_formatted\", StringType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"artists_sort\", StringType(), True),\n",
    "\n",
    "    StructField(\"master_id\", LongType(), True),\n",
    "    StructField(\"master_url\", StringType(), True),\n",
    "\n",
    "    StructField(\"num_for_sale\", IntegerType(), True),\n",
    "    StructField(\"lowest_price_value\", DoubleType(), True),\n",
    "    StructField(\"lowest_price_currency\", StringType(), True),\n",
    "    StructField(\"blocked_from_sale\", BooleanType(), True),\n",
    "\n",
    "    StructField(\"date_added_ts\", TimestampType(), True),\n",
    "    StructField(\"date_changed_ts\", TimestampType(), True),\n",
    "\n",
    "    StructField(\"have\", IntegerType(), True),\n",
    "    StructField(\"want\", IntegerType(), True),\n",
    "    StructField(\"rating_count\", IntegerType(), True),\n",
    "    StructField(\"rating_average\", DoubleType(), True),\n",
    "    StructField(\"submitter_username\", StringType(), True),\n",
    "    StructField(\"submitter_resource_url\", StringType(), True),\n",
    "\n",
    "    StructField(\"thumb\", StringType(), True),\n",
    "\n",
    "    StructField(\"artists_json\", StringType(), True),\n",
    "    StructField(\"labels_json\", StringType(), True),\n",
    "    StructField(\"companies_json\", StringType(), True),\n",
    "    StructField(\"formats_json\", StringType(), True),\n",
    "    StructField(\"identifiers_json\", StringType(), True),\n",
    "    StructField(\"genres_json\", StringType(), True),\n",
    "    StructField(\"styles_json\", StringType(), True),\n",
    "    StructField(\"tracklist_json\", StringType(), True),\n",
    "    StructField(\"videos_json\", StringType(), True),\n",
    "    StructField(\"images_json\", StringType(), True),\n",
    "    StructField(\"extraartists_json\", StringType(), True),\n",
    "    StructField(\"community_contributors_json\", StringType(), True),\n",
    "\n",
    "    StructField(\"error\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_api = spark.createDataFrame(rows, schema=schema)\n",
    "\n",
    "display(df_api.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e34703d-844a-4986-992b-9a0c5869115a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Persistieren\n",
    "# ------------------------------------------------------------\n",
    "(df_api.write\n",
    " .mode(\"append\")\n",
    " .format(\"delta\")\n",
    " .saveAsTable(\"swi_audience_prd.discogs.vinyl_release_api_stats\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b0fd602-5387-4222-bad0-3d264f596591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save the enriched results as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "071eec4b-c799-45c4-8b7d-a9464e488242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_api = spark.read.table(\"swi_audience_prd.discogs.vinyl_release_api_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f33f1091-93a4-4001-a974-2182d052e869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"/Volumes/swi_audience_prd/discogs/gold\"\n",
    "tmp_dir  = f\"{base_dir}/_tmp_vinyl\"\n",
    "final_file = f\"{base_dir}/vinyl.parquet\"\n",
    "\n",
    "# 1) Als Single-File in temporären Ordner schreiben\n",
    "(df_api\n",
    " .coalesce(1)\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .parquet(tmp_dir)\n",
    ")\n",
    "\n",
    "# 2) Die erzeugte part-Datei finden\n",
    "files = dbutils.fs.ls(tmp_dir)\n",
    "part_file = [f.path for f in files if f.name.startswith(\"part-\")][0]\n",
    "\n",
    "# 3) In gewünschte Zieldatei verschieben/umbenennen\n",
    "dbutils.fs.mv(part_file, final_file)\n",
    "\n",
    "# 4) Temp-Ordner aufräumen\n",
    "dbutils.fs.rm(tmp_dir, recurse=True)\n",
    "\n",
    "final_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "861a8b7b-1986-4542-b8bb-9ff61e8aa405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## **Manual Work Note: Export and Upload CSV to GitHub**\n",
    "## \n",
    "\n",
    "1. **Find the CSV file in Databricks:**\n",
    "   - The CSV was saved to:  \n",
    "     `/Volumes/swi_audience_prd/discogs/gold/`\n",
    "   - [Download the CSV file from Databricks](https://adb-4119964566130471.11.azuredatabricks.net/explore/data/volumes/swi_audience_prd/discogs/gold?o=4119964566130471&volumePath=%2FVolumes%2Fswi_audience_prd%2Fdiscogs%2Fgold)  \n",
    "     *(You may need to navigate to the \"Data\" tab in Databricks, browse to the path above, and use the UI to download the file.)*\n",
    "\n",
    "2. **Log in to GitHub:**\n",
    "   - Go to: https://github.com/Tao-Pi/CAS-Applied-Data-Science/tree/main/Hidden%20Grooves/ZZ%20-%20Data\n",
    "\n",
    "3. **Upload the CSV file:**\n",
    "   - Click \"Add file\" > \"Upload files\"\n",
    "   - Drag and drop the downloaded CSV file, or use the file picker.\n",
    "   - Commit the upload to the repository.\n",
    "1. **Find the CSV file in Databricks:**\n",
    "   - The CSV was saved to:  \n",
    "     `/Volumes/swi_audience_prd/discogs/gold/`\n",
    "   - [Download the CSV file from Databricks](https://adb-4119964566130471.11.azuredatabricks.net/explore/data/volumes/swi_audience_prd/discogs/gold?o=4119964566130471&volumePath=%2FVolumes%2Fswi_audience_prd%2Fdiscogs%2Fgold)  \n",
    "     *(You may need to navigate to the \"Data\" tab in Databricks, browse to the path above, and use the UI to download the file.)*\n",
    "\n",
    "2. **Log in to GitHub:**\n",
    "   - Go to: https://github.com/Tao-Pi/CAS-Applied-Data-Science/tree/main/Hidden%20Grooves/data\n",
    "\n",
    "3. **Upload the CSV file:**\n",
    "   - Click \"Add file\" > \"Upload files\"\n",
    "   - Drag and drop the downloaded CSV file, or use the file picker.\n",
    "   - Commit the upload to the repository."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5288354023429672,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01-Enrich_Raw_Data_And_Write_csv",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
